# 1. Java IO

IO流的划分

- 按照流的流向分，可以分为输入流和输出流；
- 按照操作单元划分，可以划分为字节流和字符流；
- 按照流的角色划分为节点流和处理流。

IO 流的 4 个抽象类基类:

- InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。
- OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。

节点流：直接从数据源或目的地读写数据

- 字符串 StringReader StringWriter 对字符串进行处理的节点流。
- 数 组 ByteArrayInputStream ByteArrayOutputStream CharArrayReader CharArrayWriter 对数组进行处理的节点流（对应的不再是文件，而是内存中的一个数组）。
- 管 道 PipedInputStream PipedOutputStream PipedReaderPipedWriter对管道进行处理的节点流。

处理流：连接在已存在的流（节点流或处理流）之上，通过对数据的处理为程序提供更为强大的读写功能

- 缓冲流
- 转换流：符合了适配器设计模式。
- 数据流：DataInputStream/DataOutputStream
- 对象流

---

BIO

- 同步并阻塞(传统阻塞型), 服务器实现模式为`一个连接一个线程`

- 即客户端有连接请求时服务器端就需要启动一个线程进行处理, 如果这个连接不做任何事情会造成不必要的线程开销 

NIO

- `同步非阻塞`，服务器实现模式为`一个线程处理多个请求(连接)`
- 即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有 I/O 请求就进行处理
- 适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，弹幕系统，服务器间通讯等

AIO

- `异步非阻塞`，服务器实现模式为`一个有效请求一个线程`

- 客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，一般适用于连接数较多且连接时间较长的应用
- 适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用 OS 参与并发操作

# 2. IO 模型

**一个输入操作通常包括两个阶段:**

- 等待数据就绪，并写入内核缓冲区
- 把数据从内核缓冲区复制到应用进程缓冲区

同步 和 异步： 数据复制阶段

- 同步：调用方主动获取结果
- 异步：被调者在完成后通知调用者

阻塞 和 非阻塞： 等待数据到达阶段的操作

- 阻塞：数据未到达，进程会被挂起，什么都不做
- 非阻塞：数据未到达，进程不会被挂起, 返回会不断轮训

五大模型

阻塞IO:    应用程序发起 read 调用后，会一直阻塞，直到在内核把数据拷贝到用户空间。

![img](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/1492928416812_4.png)

非阻塞IO：  

- 应用程序不会被阻塞，而是采用轮询的方式直到数据到达内核缓冲区
- 然后发起系统调用把数据从内核态拷贝到用户态

![img](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/1492929000361_5.png)

IO多路复用：

- 使用select，poll，epoll阻塞等待多个套接字中的任何一个变为可读可写事件
- 当某个套接字可读可写时，就可以发送`系统调用(recvfrom,也就是 read)`把数据从内核复制到用户态

![img](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/1492929444818_6.png)

信号驱动IO: 

- 发起一个系统调用就立即返回，应用程序继续执行
- 当数据到达内核态时发送一个就绪通知给应用进程，应用进程在发起系统调用去把数据拷贝到用户态。

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/1492929553651_7.png" alt="img" style="zoom: 80%;" />

异步IO：    

- 发起一个系统调用就立即返回，应用程序继续执行

- 当数据拷贝到用户态以后发送一个完成通知给应用进程进行处理

![img](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/1492930243286_8.png)

# 3. IO多路复用

## 3.1 什么是IO多路复用

- IO 多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄(socket)
- 没有事件发生就会阻塞应用程序，交出CPU
- 一旦有一个或多个事件发生，就能够通知应用程序进行相应的读写操作

select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll

## 3.2 select/poll

1. 将已连接的Socket都放到一个文件描述符集合，然后调用`select函数`将文件描述符`拷贝`到内核，让内核检测是否有网络事件发生
2. 检查的方式就是通过遍历文件描述符集合，当检查到有事件产生后，就将此Socket标记为可读或可写。
3. 接着把文件描述符集合拷贝回用户态
4. 用户态通过遍历的方式找到可读或者可写的Socket，对其进行处理

---

1. select使用固定长度的BitsMap来标识文件描述符集合，且其支持的文件描述符是有限制的，默认为1024个。
2. poll不再用BitsMap来存储文件描述符，而是使用以链表形式组织的 动态数组，突破了select的文件描述符个数的限制。
3. 但是poll和select区别不大，都是使用线性结构存储socket，因此都需要遍历集合来找到可读或者可写的socket，复杂度为O（N），而且也需要在用户态与内核态之间拷贝文件描述符集合

## 3.3 epoll

**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）

1. 通过**epoll_create**创建一个epoll的句柄，参数size`是对内核初始分配内部数据结构的一个建议`，返回一个文件描述符

2. 在内核中使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的socket通过`epoll_ctl()`加入到红黑树中，增删查的时间复杂度为O(logn); 通过对红黑树进行操作，就不需要像select/poll每次都要进行大量的数据拷贝，而是只需要传入一个待检测的socket就行了；

```c
// epfd：是epoll_create()的返回值。
// fd：是需要监听的fd（文件描述符）
// op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
// epoll_event：是告诉内核需要监听什么事
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
```

3. epoll使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个socket有事件发生时，通过回调函数，内核会将其加入到`就绪事件链表`中，当用户调用`epoll_wait()`函数,使用拷贝将数据从内核拷贝到用户空间，然后返回有事件发生的文件描述的个数；而不需要像select/poll那样遍历整个socket集合  

```c
// 等待epfd上的io事件，最多返回maxevents个事件。
// 参数events用来表示从内核得到事件的集合,该函数返回需要处理的事件数目，如返回0表示已超时。
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```



<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20211021161906729.png" alt="image-20211021161906729" style="zoom:80%;" />

epoll支持两种事件触发模式，分别是边缘触发(edge-triggered,ET)和水平触发模式(Level-triggered,LT)：

- 共同点： 都是通过epoll_wait从EPOLL等待队列读取激活事件。

- 使用边缘触发时，当epoll_wait检测到事件发生后，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。告知应用程序后应用程序必须立即处理该事件，后续的epoll_wait将不会再向应用程序告知这一事件。一般配合while，只支持 No-Blocking。
- 使用水平触发，当epoll_wait检测到监听文件描述符上有事件发生时通知应用程序，应用程序可以不立即处理该事件，下次调用epoll_wait时该事件还会被通告直到该事件被处理，直到内核缓冲区中的数据被read函数读完才结束。同时支持 Blocking 和 No-Blocking。

> select/pol
>
> 只有水平触发模式，epoll默认的是水平触发，但是可以设置为边缘触发模式。
>
> ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

# 4. Reactor/Proactor

## 4.1 演进

1. 最开始的时候是阻塞IO，一个连接对应一个请求。十分消耗资源
2. 之后引入线程池的概念。但是一个线程仍然只能处理一个连接，且当无数据读时，会阻塞在read
3. 将IO改为非阻塞IO，然后线程不断轮询。但是这个非常消耗CPU资源。

4. 使用IO多路复用，对I/O多路复用做一层封装，让使用者只需要关注应用代码的编写。取名为`Reactor`模式(来了一个事件，Reactor就有相对应的反应/响应)

## 4.2 Reactor

Reactor模式主要由Reactor和处理资源池这两个核心部分组成

- `Reactor`负责监听和分发事件
- `处理资源池`负责处理事件，如read -> 业务逻辑 -> send

Reactor的四种方案

- 单Reactor 单进程/线程
- 单Reactor 多进程/线程
- 多Reactor 单进程/线程（没有应用，没有优势）
- 多Reactor 多进程/线程

### 4.2.1 单Reactor 单进程/线程

1. Reactor对象通过select监听事件，收到事件后通过dispatch进行分发
2. 如果是建立连接的事件，则由Acceptor对象进行处理，Acceptor对象会通过accept方法获取连接，并创建一个handler对象来处理后续的响应事件
3. 如果不是连接事件，则交由当前连接对应的Handler对象来进行响应
4. Handler通过read -> 业务处理 -> send的流程来完成完整的业务流程

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220107162216574.png" alt="image-20220107162216574" style="zoom:50%;" />

缺点

- 因为只有一个进程，无法充分利用多核CPU
- handler如果处理时间过久，则整个进程无法处理其他连接事件，造成响应延迟

> Redis就是这种模式，因为Redis的数据都在内存中，处理数据非常快，性能瓶颈不在CPU

### 4.2.2 单Reactor 多进程/线程 

1. Reactor对象通过select监听事件，收到事件后通过dispatch进行分发
2. 如果是建立连接的事件，则由Acceptor对象进行处理，Acceptor对象会通过accept方法获取连接，并创建一个handler对象来处理后续的响应事件
3. 如果不是连接事件，则由当前连接对应的handler对象来进行响应。handler负责数据的接收和发送，其中业务代码则有子进程的Processor对象进程处理

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220107162423959.png" alt="image-20220107162423959" style="zoom:50%;" />

> 很少使用，实现复杂，且一个Reactor对象承担所有事件的监听和响应，容易成为性能的瓶颈

### 4.2.3 多Reactor多进程/线程 ☆

主线程只负责接收新连接，子线程负责后续的业务处理。主线程只需要把新的连接传给子线程，子线程无需返回数据给主进程，可以直接发送给客户端。

1. 主进程通过select只监控连接建立事件，收到事件后通过Acceptor中的accept获取连接，然后将新的连接分配给某个子线程
2. 子线程将主线程分配的连接加入到监控集合中，通过select监控读写事件，有新的事件发送，则调用对应的handler处理

![image-20220107163036095](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220107163036095.png)

> Netty使用
>
>  NIO 的<多线程优化章节>有简化版本代码

## 4.3 Proactor

Reactor是非阻塞同步网络模型，而Proactor是异步网络模型。

- Reactor是非阻塞同步网络模型，感知的是就绪可读写事件。需要应用进程主动调用read来完成数据的读取，读取完才能进行数据的处理。
- Proactor是异步网络模型，感知的是已完成的读写事件。由操作系统内核自动帮我们完成数据的读写工作，并不需要应用进程来read/write，只需要完成数据的处理就行

# 5. 零拷贝

传统的读写一次文件需要`4次内核态/用户态切换`,`四次数据拷贝`

- DMA将数据从磁盘拷贝到操作系统内核缓冲区
- CPU将数据从内核缓冲区拷贝到用户缓冲区
- CPU将数据从用户缓冲区拷贝到内核的socket发送缓冲区
- DMA将内核的socket发送缓冲区的数据拷贝到网卡的缓冲区
- 其中四次内核态/用户态的切换，因为发生了系统调用（read和write),每次都先切换到内核态，完成任务后切换回用户态

---

要想提高文件传输的性能，就需要减少`用户态和内核态的切换`和`内存拷贝次数`

1. 减少`用户态和内核态的切换`：就需要减少系统调用，因为一次系统调用会导致两次切换
2. 减少`内存拷贝次数`：文件传输中，用户态不会对数据进行下加工，所以可以不用将数据拷贝到用户空间

实现零拷贝： 不用将数据拷贝到用户态中

---

mmap + write：

- 调用`mmap()`,`内核中读缓冲区`的地址与`用户空间的缓冲区`进行映射，实现`共享`,接着DMA把磁盘的数据拷贝到内核的缓冲区，`DMA搬运数据`
- 应用进程调用`write`，CPU将内核缓冲区的数据拷贝到socket缓冲区中。`CPU搬运数据`
- DMA将socket的数据拷贝到网卡的缓冲区。`DMA搬运数据`
- 四次上下文切换，三次拷贝（两次DMA,一次CPU）

<img src="https://aikaid-img.oss-cn-shanghai.aliyuncs.com/img-2022/image-20221001144924786.png" alt="image-20221001144924786" style="zoom:33%;" />

sendfile： 

-  DMA 控制器将数据从磁盘拷贝到内核空间的读缓冲区。
-  调用`sendfile()`系统调用将读缓冲区 (read buffer) 中的数据拷贝到socket缓冲区 (socket buffer)。
-  CPU 利用 DMA 控制器将数据从网络缓冲区 (socket buffer) 拷贝到网卡进行数据传输。
-  只有一次系统调用，所以只有2次上下文切换，还有3次拷贝

<img src="https://aikaid-img.oss-cn-shanghai.aliyuncs.com/img-2022/image-20221001144913754.png" alt="image-20221001144913754" style="zoom:33%;" />

sendfile + DMA gather copy

- 调用`sendfile()`，从用户态陷入内核态；
- DMA使用scatter功能把数据从磁盘拷贝到内核缓冲区进行离散存储
- CPU把包含内存地址和数据长度的缓冲区描述符拷贝到socket缓冲区
- DMA控制器根据socket缓冲区里的内存地址和数据大小，使用scatter-gather技术从内核缓冲区收集数据放到网卡缓冲区中
- 只有一次系统调用，2次上下文切换，两次DMA拷贝，无CPU拷贝

<img src="https://aikaid-img.oss-cn-shanghai.aliyuncs.com/img-2022/image-20221001144855139.png" alt="image-20221001144855139" style="zoom:33%;" />


> KAFKA,NGINX都可以开启零拷贝

NIO的零拷贝由transferTo()方法实现，本质上是调用sendfile()系统调用



# 6. 直接内存

直接内存定义: 

- Java中的NIO通过直接内存(mmap)将JVM堆内存 和 操作系统内核内存映射起来
- 通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作。

- 避免了数据在Java内存 和 操作系统内存之间的数据拷贝

直接内存优缺点:

- 读写效率高, 分配效率低
- 不受 GC 影响

直接内存使用场景

- 有很大的数据需要存储，它的生命周期又很长
- 适合频繁的IO操作，比如网络并发场景
