> 用于分类的KNN

k-近邻（kNN, k-NearestNeighbor）算法

1. 特点:

- `输入`为实例的特征向量，对应于特征空间的点; `输出`为实例的类别，可以取多类
- k 近邻算法利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。 k值的选择、距离度量以及分类决策规则是k近邻算法的三个基本要素。

2. 工作原理:

- 假设有一个带有标签的样本数据集（训练样本集），其中包含每条数据与所属分类的对应关系
- 输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较
  - 计算新数据与样本数据集中每条数据的距离
  - 对求得的所有距离进行排序（从小到大，越小表示越相似）
  - 取前 k （k 一般小于等于 20 ）个样本数据对应的分类标签
- 求 k 个数据中出现次数最多的分类标签作为新数据的分类

3. 开发流程:

- 收集数据: 任何方法 
- 准备数据: 距离计算所需要的数值，最好是结构化的数据格式 
- 分析数据: 任何方法 
- 训练算法: 此步骤不适用于 k-近邻算法 
- 测试算法: 计算错误率 使用算法: 输入样本数据和结构化的输出结果，然后运行 k-近邻算法判断输入数据分类属于哪个分类，最后对计算出的分类执行后续处理

4. 优缺点:

- 优点: 精度高、对异常值不敏感、无数据输入假定
- 缺点: 计算复杂度高、空间复杂度高
- 适用数据范围: 数值型和标称型

