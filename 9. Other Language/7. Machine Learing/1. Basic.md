# 1. 简介

监督学习: Learns from being given right ansewers

非监督学习: Data only comes with inputs x, but not output labels y; Algorithm has to find `structure` in the data

## 1.1 监督学习

定义:

- 必须确定目标变量的值，以便机器学习算法可以发现`特征`和`目标变量`之间的关系
- 训练样本 = 特征(feature) + 目标变量(label: 分类-离散值/回归-连续值)

需要注意的问题:

- 偏置方差权衡
- 功能的复杂性和数量的训练数据
- 输入空间的维数
- 噪声中的输出值

主要场景:

- `Regression`: Predict a number which from infinitely many possible outputs, 主要用于预测数值型数据

- `Classification`: predict categories, 将实例数据划分到合适的类别中

<img src="/Users/alkaid/Library/Application Support/typora-user-images/image-20220807180429868.png" alt="image-20220807180429868" style="zoom:50%;" />

## 1.2 非监督学习

- `Clustering`: Group similar data points together

- `Dimensionality reduction`: Compress data using fewer numbers

- `Anomaly detection`: Find unusual data points

## 1.3 术语

- m: 代表训练集中实例的数量
- x: input / feature
- y: output / target
- $$y-hat$$: y的估计值
- (x,y): single training example
- $$(x^{(i)},y^{(i)})$$: 代表第 i 个观察实例：其中$$x^{(i)}$$ 代表第i个输入变量, $$y^{(i)}$$代表第i个目标变量
- h: 代表学习算法的解决方案或函数，也称为假设（hypothesis）

拟合程度:

- 欠拟合（Underfitting）: 模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。类比，光看书不做题觉得自己什么都会了，上了考场才知道自己啥都不会。
- 过拟合（Overfitting）: 模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。类比，做课后题全都做对了，超纲题也都认为是考试必考题目，上了考场还是啥都不会。

模型:

- 分类问题 —— 说白了就是将一些未知类别的数据分到现在已知的类别中去。比如，根据你的一些信息，判断你是高富帅，还是穷屌丝。评判分类效果好坏的三个指标就是上面介绍的三个指标: 正确率，召回率，F值。
- 回归问题 —— 对数值型连续随机变量进行预测和建模的监督学习算法。回归往往会通过计算 误差（Error）来确定模型的精确性。
- 聚类问题 —— 聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。聚类问题的标准一般基于距离: 簇内距离（Intra-cluster Distance） 和 簇间距离（Inter-cluster Distance） 。簇内距离是越小越好，也就是簇内的元素越相似越好；而簇间距离越大越好，也就是说簇间（不同簇）元素越不相同越好。一般的，衡量聚类问题会给出一个结合簇内距离和簇间距离的公式。

# 2. 模型评价

## 2.1 评估方法

## 2.2 评估指标

<img src="https://img2020.cnblogs.com/blog/1787018/202004/1787018-20200402200343857-1498193641.png" alt="img" style="zoom:50%;" />

- 召回率(recall): 某个绿色值除以当前行之和, 所有真的正样本中到底有多少被检测出来
- 查准率(precision): 某个绿色值除以当前列之和, 预测为正的样本中有多少是真的正样本
- 准确率(accuracy): 对角线之和除以总和, 
- precision和recall是一对矛盾体，前者体现的是预测的正例靠不靠谱，后者体现的是漏检率

PR曲线:

- 可以直观看出precision随着recall增大的变化率。如果曲线越接近右上角，就说明随着recall的增加，precision往下掉的速度不明显
- 用于评估更看重正例的情况

F1 值:

- 查准率和查全率的调和平均值, 如果希望F1值高，则需要两者都比较高且均衡

<img src="https://img2020.cnblogs.com/blog/1787018/202004/1787018-20200406170830801-1813974583.png" alt="img" style="zoom:50%;" />

ROC曲线:

- 用于评估分类器的整体性能，以及需要剔除类别不平衡影响的情况



分析下现在的局势:

1. 前提: 今年的 hc 不太可能比去年多
2. 竞争对手层面: 基座那边有 6 个人, 鸟姐组, 迁移组, 管控组, 
3. 学历层面: 
4. 选择: 秋招 or 答辩
5. 有点不想选择答辩的理由: 

- 
