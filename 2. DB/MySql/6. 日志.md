**物理日志与逻辑日志**

- 物理日志记录：数据页的变更
- 逻辑日志记录：SQL语句

> bin log，redo log，undo log三个都是WAL日志

# 1. bin log

## 1.1 简介

binlog 的 特点

- 记录了所有的DDL 和 DML语句，但是不记录查询语句； 默认情况下是不开启的
- 是逻辑日志，采用二进制进行存储
- 可以用于数据恢复 和 Mysl主存复制

## 1.2 二进制日志格式

**二进制日志格式**: 可以通过`binlog_format`参数指定。

- `statement`：记录的是SQL语句
- `row`: 记录的是行更改信息，因此占据的存储空间比statement大
- `mixed`：混合了STATEMENT和ROW两种格式。8.0默认模式
  - 一般的更新语句使用 Statement 模式来保存 Binlog
  - 但是遇到一些函数操作，可能会影响数据准确性的操作则使用 Row 模式来保存。

## 1.3 写入时机

事务执行过程中，先把日志写到 binlog cache；

write 和 fsync 的时机，是由参数 sync_binlog 控制的：

1. sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；
2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

> 但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

# 2. redo log 

事务的原子性， 一致性， 持久性 通过数据库的redo log来实现

## 2.1 为什么需要redo log

- 因为数据是存放在磁盘中的，而想要对数据增删改查的话，首先会将数据页加载进内存的Buffer Pool，然后在Buffer Pool中进行修改；
- 如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

解决方法一： 在事务提交以前就把该事务所修改的所有页面都刷新到磁盘中

- 因为脏页中可能只有1-2个字节被修改了, 而为了这几个字节的数据就进行频繁的刷盘的话，十分影响性能
- 一个事务可能修改了多个页面，这些页面如果不相邻的话，那么就需要在进行随机IO，十分影响性能

解决方法二： redo log来记录事务对于数据库的修改

- `占用空间小`：如果是写 `redo log`，一行记录可能就占几十 `Byte`，只包含表空间号、数据页号、磁盘文件偏移 量、更新值
- `顺序IO`: 日志是按照产生的顺序写入磁盘的，是顺序IO，所以刷盘速度很快。

## 2.2 redo log的格式

| type      | space ID | page number | data     |
| --------- | -------- | ----------- | -------- |
| log的类型 | 表空间ID | 页号        | 具体内容 |

## 2.3 写入时机

redo log有三种状态

- 存在redo log buffer中
- 存在于page cache中(调用write，但是没有调用fsync)
- 存在于磁盘中(调用fsync)

---

- 后台线程每隔1s，将redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。
- **redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候**，会将redo log写入到page cache中
- **innodb_flush_log_at_trx_commit** 参数
  - 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;
  - 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；
  - 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

## 2.4 日志文件组

- redo log在磁盘中以日志文件组的形式出现，一个组有多个redo log文件，每个文件的大小都一样
- 采用环形数组形式，从头开始写，写到末尾又回到头循环写
- 有两个重要属性：write pos、checkpoint
- **write pos** 是当前记录的位置，一边写一边后移；刷盘时，write pos后移
- **checkpoint** 是当前要擦除的位置，也是往后推移； 加载日志文件组进行恢复时，`checkpoint` 后移更新。
- `write pos` 和 `checkpoint` 之间的还空着的部分可以用来写入新的 `redo log` 记录。

## 2.5 有了redo log为什么还要脏页刷新

既然有重做日志保证数据持久性，查询时也可以直接从缓冲池页中取数据，那为什么还要刷新脏页到磁盘呢？

如果重做日志可以无限增大，同时缓冲池足够大，能够缓存所有数据，那么是不需要将缓冲池中的脏页刷新到磁盘。但是，通常会有以下几个问题：

- 服务器内存有限，缓冲池不够用，无法缓存全部数据
- 重做日志无限增大成本要求太高
- 宕机时如果重做全部日志恢复时间过长

## 2.6 redo log 与 bin log区别

- redo log是InnoDB引擎实现的，不是所有引擎都有； bin log是Server层实现的，所有引擎都有

- redo log物理日志，bin log是逻辑日志(根据 binlog_format 参数的不同，形式不同)
- redo log固定大小，采用循环写； bin log 无限大小，采用追加写
- redo log使用于崩溃恢复(crash -safe),保证持久性； bin log适合于主从复制 和 基于时间点的数据恢复

## 2.7 两阶段提交

为什么需要两阶段提交：

- 为了保证binlog和redo log两份日志的逻辑一致，最终保证恢复到主备数据库的数据是一致的
- 否则的话，在第一个日志写完，第二个日志还没有写完期间发送了crash，会导致两个日志逻辑不一致
- 先写redo log 后写 bin log； 数据库可以通过redo log把数据恢复过来；但是因为binlog没有记录这个语句，所以当使用bin log恢复库的话，就会少了这个更新，导致和原库的值不同
- 先写 bin log 后写 redo log；redo log没有记录对应的数据，所以通过redo log恢复的话，事务的更改无效；但是通过bin log恢复的话，会有对应的数据更改，导致与原库的值不同

两阶段提交流程： redo log的提交分为prepare和commit两个阶段，所以称之为**两阶段提交** 。

- 事务的更新记录到内存后，将修改操作记录写入到redo log中，处于prepare状态
- 然后bin log写入
- 最后提交事务的时候，将redo log状态改为commit（这个操作是不会失败的）

数据恢复的流程

- 两个日志都没写入的话，那么事务无效，回滚事务
- redo log 处于prepare，bin log没写入的话，则判断对应的事务 binlog 是否存在并完整：完整则事务有效；否则事务无效

> redo log 和 binlog 有一个共同的数据字段叫 XID，就根据 XID 去 binlog 中判断对应的事务是否存在并完整

- 两个日志都写入了，说明redo log处于commit，则事务有效

## 2.8 只靠bin log可以支持数据库崩溃恢复吗？

1. binlog记录的是数据行的修改，没有记录数据页修改的详细信息，不具备恢复数据页的能力。
2. 事务提交后，如果binlog没有写入到磁盘中，那么还是没有实现持久化

# 3. undo log 

**undo log的特点**

- undo log是逻辑日志，记录的是SQL语句；可以根据undo log 逆推出以往事务的数据
- undo log也会产生redo log，因为undo log也需要持久性保护
- 可以用于事务的回滚和 MVCC

**undo log为什么是逻辑日志：**

- 因为在多并发系统中，可能会有多个事务对同一个页进行修改；
- 如果undo log是物理日志的话，那么rollback以后可能造成其他事务对于该页的操作被消除了；

**undo log存储管理**

- 每个回滚段(rollback segment)中有 1024 个 undo log segment; 每个undo log segment会进行undo页的申请
- InnoDB1.1版本以前，只有一个rollback segment，因此最多支持1024个事务
- 1.1 开始支持 128 个 rollback segment，因此在线事务最多128 * 1024

**undo log的分类**

- insert undo log：事务在 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃
- update undo log：事务在进行 update 或 delete 时产生的 undo log，在事务回滚时需要，在MVCC时也需要。不能随意删除，只有在快照读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除

> 每次对数据库记录进行改动，都会将旧值放到一条 undo 日志中，算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被 roll_pointer 属性连接成一个链表，把这个链表称之为**版本链**，版本链的头节点就是当前记录最新的值，链尾就是最早的旧记录

# 4. 错误日志

- 记录的内容： 启动/停止/运行时发送的错误信息
- 存放位置：  默认存放目录为 mysql 的数据目录（var/lib/mysql）

```mysql
# 查看日志位置
SHOW VARIABLES LIKE 'log_error%';
# 查看日志内容：
tail -f /var/log/mysql/error.log
```

- 默认是开启的

# 5. 查询日志

- 记录的内容： 记录了客户端的所有操作语句，默认是不开启的
- 开启查询日志

```mysql
# 配置 my.cnf：
# 该选项用来开启查询日志，可选值0或者1，0代表关闭，1代表开启 
general_log=1
# 设置日志的文件名，如果没有指定，默认的文件名为host_name.log，存放在/var/lib/mysql
general_log_file=mysql_query.log
```

# 6. 慢查询日志

- 记录的内容：记录所有执行时间超过 long_query_time 并且扫描记录数不小于 min_examined_row_limit 的所有的 SQL 语句。long_query_time 默认为 10 秒，最小为 0， 精度到微秒
- 文件的位置: 慢查询日志默认是关闭的，可以通过两个参数来控制慢查询日志，配置文件 `/etc/mysql/my.cnf`：
- 

```sh
# 该参数用来控制慢查询日志是否开启，可选值0或者1，0代表关闭，1代表开启 
slow_query_log=1 

# 该参数用来指定慢查询日志的文件名，存放在 /var/lib/mysql
slow_query_log_file=slow_query.log

# 该选项用来配置查询的时间限制，超过这个时间将认为值慢查询，将需要进行日志记录，默认10s
long_query_time=10
```

- 日志读取: cat 或者　mysqldumpslow 