

# 1. Redis为什么那么快

1. 内存: 所有的数据都是放在内存中的，而内存的访问速度很快
1. C 语言: 底层使用 C 语言实现，C 语言实现的程序距离操作系统更近，执行速度相对会更快
1. 单线程: 预防了多线程可能产生的竞争问题, 也避免了上下文的频繁切换
1. 高效的数据结果: 一个对象可能有多个对应的数据结构
1. IO 多路复用: 可以同时监控多个 socket, 单线程可以高效处理多个请求



# 2. Redis为什么是单线程

- 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。
- 好处：**不需要各种锁的性能消耗**

# 3. Redis缓存

## 3.1 缓存雪崩

1. 出现原因：缓存在某一个时刻出现大规模的key失效，导致大量的请求访问直接请求数据库，导致数据库服务器无法抗住请求或挂掉的情况。这时网站常常会出现 502 错误，导致网站不可用问题。

2. 解决方案

- **合理规划缓存的失效时间(事前)**: 可以给缓存时间加一个随机数，防止统一时间过期
- **采用多级缓存方案(事前)**。例如：本地缓存（Ehcache/Caffine/Guava Cache） + 分布式缓存（Redis/ Memcached）
- **增加缓存系统可用性(事前)**。例如：部署 Redis Cluster（主从+哨兵），以实现 Redis 的高可用，避免全盘崩溃
- **热点数据缓存永远不过期(事前)**: 针对热点key不设置过期时间
- **限流、降级、熔断方案（事中）**，避免被流量打死。如：使用 Hystrix 进行熔断、降级
- **持久化(事后)**: 缓存如果支持持久化，可以在恢复工作后恢复数据（事后）。如：Redis 支持持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据

## 3.2 缓存击穿

出现原因：缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库。

解决方法：关键在于某个热点的key失效了，导致大并发集中打在数据库上。所以要从两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。

- **定时异步刷新, 使得热点数据永不过期**：可以对部分数据采取失效前自动刷新的策略，而不是到期自动淘汰。淘汰其实也是为了数据的时效性，所以采用自动刷新也可以
- **分布式锁**：锁住热点数据的 key，避免大量线程同时访问同一个 key。

## 3.3 缓存穿透

出现原因：查询的数据在数据库中不存在，那么缓存中自然也不存在。所以，应用在缓存中查不到，则会去查询数据库。当这样的请求多了后，数据库的压力就会增大

解决方法：缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis中是不存在的。

- 使用布隆过滤器：将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。
- 缓存空对象：当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value="null"，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。

## 3.4 缓存预热

缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。

如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

- 数据量不大的时候，工程启动的时候进行加载缓存动作；
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存。

## 3.5 缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。

## 3.6 缓存一致性(TODO)

> https://www.cnblogs.com/rjzheng/p/9041659.html

写入是先写数据库 然后 删除旧的缓存

- 为什么是删除旧的缓存 而不是更新呢：
- 为什么是先数据库再缓存呢：

> 1. 线程A发起一个写操作，第一步del cache
> 2. 此时线程B发起一个读操作，cache miss
> 3. 线程B继续读DB，读出来一个老数据
> 4. 然后线程B把老数据设置入cache
> 5. 线程A写入DB最新的数据
>
> 缓存保存的是老数据，数据库保存的是新数据。从而数据不一致

如何保证缓存一致性：是CAP中的AP模型

- 延时双删策略：
  - 先删除缓存，再更新数据库，休眠一会（比如1秒），再次删除缓存。
- 删除缓存重试机制：不管是延时双删还是Cache-Aside的先操作数据库再删除缓存，如果第二步的删除缓存失败呢?会导致脏数据
  - 写请求更新数据库；缓存因为某些原因，删除失败；
  - 把删除失败的key放到消息队列
  - 从消息队列获取要删除的key
  - 重试删除缓存操作
- 读取big log异步删除缓存：重试删除缓存机制还可以，就是会造成好多业务代码入侵。
  - 一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。
  - canal框架可以实现

# 4. Redis使用场景

- 缓存:
- 分布式锁
- 排行榜：使用Zset(有序集合)
- 计算器/限速器：
  - 利用 Redis 中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等。
  - 限制某个用户访问某个 API 的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；
- 好友关系：利用集合的一些命令，比如求交集、并集、差集等。
- 消息队列：使用list实现一个队列机制，比如到货通知，邮件发送等
- Session共享：

不适合场景：数据量大，访问频率太低的

# Hot Key

1. 多缓存副本: 预先感知到发生热点访问的key，生成多个副本key，这样可以保证热点key会被多个缓存服务器持有; 访问时可随机访问N个备份中的一个，进一步分担读流量
2. 本地缓存: 也就是JVM本地缓存, 针对热点key外面包一层短存活期的本地缓存，用于缓冲热点服务器的压力
3. Redis集群扩容：增加分片副本，均衡读流量

# Big Key
