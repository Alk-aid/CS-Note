# 1. 分布式锁

**目的**：使用分布式锁来限制程序的并发执行。

**格式**：用lua脚本实现加锁和解锁的的原子性

```sh
// 原子性加锁并设置过期时间
set <key> true ex <seconds> nx
del <key>
```

**演化：**

- 开始是setnx <key> true(加锁操作)
- 但是如果执行过程中出现了异常，那么这个锁就永远得不到释放；所以需要添加一个过期事件expire <key> <seconds>
- 但是如果setnx 和 expire执行之间出现了错误，那么还是会出现死锁情况。所以setnx 和 expire操作应该是原子性的
- 使用事务是不行的，因为Redis的事务不是原子性的，会出现没抢到锁还是执行了expire

**超时问题**：

- 因为业务执行流程较长，使得到了过期时间而业务代码未执行完就自动释放锁
- 守护线程解决方案：额外起一个线程，定期检查线程是否还持有锁，如果有则延长过期时间。有和引入redlock相同的问题
- 超时回滚解决方案：当我们解锁时发现锁已经被其他线程获取了，说明此时我们执行的操作已经是“不安全”的了，此时需要进行回滚，并返回失败。

**可重入性**： Java中需要配合ThreadLocal来实现可重入性

**加锁失败**：

- `直接抛出异常，通知客户端稍后重试`：适合于由用户直接发起的请求，用户看到错误后，自己点重试，起到人工延时的作用
- `sleep以后然后重试`：会阻塞当前的消息处理线程，容易造成消息处理有延时
- `将请求转移至延时队列中，过一会再试`：将消息序列化作为zset的value，过期时间作为score，放入到zset中；多个线程轮询zset获取到期的任务进行处理。

**RedLock算法**

- `出现原因`：在集群模式下，可能出一个客户端在主节点申请一把锁，但是这个锁还未同步到从节点，主节点就挂掉了；导致另一个客户端请求加锁时，新的主节点立刻就批准了；导致一把锁背多个客户端持有
- 需要提供多个Redis实例，加锁时向过半结点发送set(key,valie,nx = True,ex = xxx)指令，只要过半结点set成功，则认为加锁成功

---

Zookeeper方案：安全性更好

1、创建一个锁目录 /locks，该节点为持久节点

2、想要获取锁的线程都在锁目录下创建一个临时顺序节点

3、获取锁目录下所有子节点，对子节点按节点自增序号从小到大排序

4、判断本节点是不是第一个子节点，如果是，则成功获取锁，开始执行业务逻辑操作；如果不是，则监听自己的上一个节点的删除事件

5、持有锁的线程释放锁，只需删除当前节点即可。

6、当自己监听的节点被删除时，监听事件触发，则回到第3步重新进行判断，直到获取到锁。

# 2. 异步消息队列

**使用须知**：对于消息的可靠性要求不高，只有一组消费者的消息队列

**实现**：使用list来实现异步消息队列

**队列空**： 

- 为了防止空轮询，使用sleep让线程睡一会；但是会造成消息的延迟增大
- 使用`blpop/brpop`（阻塞读）：队列没数据被阻塞，队列有数据则可以直接醒过来处理；如果线程一直阻塞，服务器会断开连接

# 3. 缓存

## 3.1 缓存雪崩

出现原因：缓存在某一个时刻出现大规模的key失效，导致大量的请求访问直接请求数据库，导致数据库服务器无法抗住请求或挂掉的情况。这时网站常常会出现 502 错误，导致网站不可用问题。

解决方法：导致缓存雪崩的主要原因就是大规模的key失效

事前

- 合理规划缓存的失效时间，可以给缓存时间加一个随机数，防止统一时间过期；
- 可以考虑多级缓存设计，第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。
- 热点数据缓存永远不过期：
  - 物理不过期，针对热点key不设置过期时间
  - 逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建

事中：

- 使用互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降
- 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。

事后：

-  开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。

## 3.2 缓存击穿

出现原因：缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库。

解决方法：关键在于某个热点的key失效了，导致大并发集中打在数据库上。所以要从两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。

- 热点数据缓存永远不过期。
- 在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降

## 3.3 缓存穿透

出现原因：用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。高并发访问这个数据的话，会导致短时间大量请求落在数据库上，造成数据库压力过大。

解决方法：缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis中是不存在的。

- 使用布隆过滤器：将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。
- 缓存空对象：当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value="null"，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。

## 3.4 缓存预热

缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。

如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

- 数据量不大的时候，工程启动的时候进行加载缓存动作；
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存。

## 3.5 缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。

## 3.6 缓存和数据库的一致性

# 4. 一致性hash

原本的hash算法存在的问题：

- 当机器数增加或者减少时，那么映射关系就发生了改变(举例)，从而导致大量缓存的key失效，造成缓存雪崩

一致性hash算法

- 通过hash环来实现，hash环的大小是2^32次方；首先将服务器(用IP或者主机名)通过hash映射放到hash环上；然后再将数据也通过hash映射放到hash环上面；然后在hash环上进行顺时针查找距离这个对象最近的一个服务器，让这个服务器缓存这个数据即可

优势：

- 良好的扩展性；当增加了服务器或者减少了，会导致一小部分缓存失效，大部分的缓存key仍然可用。

一致性hash算法的问题

- hash偏斜：如果服务器没有均匀的分布在hash环上，导致缓存大部分分布在一个服务器上，导致缓存不均匀，使得服务器没有得到良好的使用，一旦缓存失效，容易引起系统的崩溃
- 解决方案：引入虚拟结点。将一个真实结点映射为多个虚拟结点。从而缓存读写的流程变成(先找到虚拟结点，再找到真实结点然后进行读取)

# 5. Redis和DB的一致性

写入是先写数据库 然后 删除旧的缓存

- 为什么是删除旧的缓存 而不是更新呢：
- 为什么是先数据库再缓存呢：

> 1. 线程A发起一个写操作，第一步del cache
> 2. 此时线程B发起一个读操作，cache miss
> 3. 线程B继续读DB，读出来一个老数据
> 4. 然后线程B把老数据设置入cache
> 5. 线程A写入DB最新的数据
>
> 缓存保存的是老数据，数据库保存的是新数据。从而数据不一致

如何保证缓存一致性：是CAP中的AP模型

- 延时双删策略：
  - 先删除缓存，再更新数据库，休眠一会（比如1秒），再次删除缓存。
- 删除缓存重试机制：不管是延时双删还是Cache-Aside的先操作数据库再删除缓存，如果第二步的删除缓存失败呢?会导致脏数据
  - 写请求更新数据库；缓存因为某些原因，删除失败；
  - 把删除失败的key放到消息队列
  - 从消息队列获取要删除的key
  - 重试删除缓存操作
- 读取big log异步删除缓存：重试删除缓存机制还可以，就是会造成好多业务代码入侵。
  - 一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。
  - canal框架可以实现

