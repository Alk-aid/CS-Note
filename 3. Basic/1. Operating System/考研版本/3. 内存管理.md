存储层次至少应有三级：CPU寄存器、主存、辅存

- CPU寄存器：寄存器
- 主存：cache，主存，磁盘缓存(实质上就是主存，只不过是代指磁盘中的数据)
- 辅存：磁盘，可移动存储介质

# 1. 存储保护

目的：

- 保护OS不被用户访问
- 保护用户进程不会相互影响，不会越界访问

实现：硬件方式

- 基地址寄存器：保存最小的合法物理地址，也就是进程的`起始物理地址`
- 界限寄存器：保存合法的地址范围大小，也就是进程的`最大逻辑地址`
- 判断方式：基地址<= 物理地址 <= （基地址 + 界限地址）

内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元，

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210907091341951.png" alt="image-20210907091341951" style="zoom:50%;" />

# 2. 地址转换

> 操作系统负责将逻辑地址转化为物理地址，实现方式就是`内存装入`的三种方式

将用户源代码 --> 可在内存中执行的程序(exe)的三个步骤

1. 编译：将源代码转化为若干个目标模块
2. 链接：将编译后形成的一组目标模块以及所需的库函数链接在一起，形成一个完整的装入模块
3. 装入：将装入模块装入内存运行

---

静态链接：

- `在程序运行之前`，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开

- 对相对地址进行修改，变换外部调用符号

装入时动态链接：

- 将各目标模块装入内存时，`边装入边链接`的链接方式。
- 便于修改和更新，便于实现对目标模块的共享

运行时动态链接：

- `在程序执行中需要该目标模块时`，才对它进行链接。
- 加快装入过程，节省大量的内存空间

---

`绝对装入`

- 编译时产生的地址使用绝对地址(物理地址)，内存中也是绝对地址
- 程序或数据被修改，需要重新编译程序

`可重定位装入(静态重定位)`

- 编译后的目标模块使用相对地址(逻辑地址), 装入后内存中指令的地址是**绝对地址（物理地址）**
- 在装入时，完成重定位，将逻辑地址变换为物理地址（地址变换是在装入时一次完成的），`需要硬件支持`
- 在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。作业一旦进入内存后，在运行期间就不能再移动，也不能再申请内存空间

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210907092921346.png" alt="image-20210907092921346" style="zoom:50%;" />

`动态运行时装入(动态重定位)`

- 编译后的目标模块使用相对地址（逻辑地址），装入内存后所有的地址依然是**逻辑地址**，运行前都是逻辑地址
- 在运行时完成重定位，这种方式需要一个**重定位寄存器**的支持
- 采用动态重定位时**允许程序在内存中发生移动**（如 可重定位分区分配）
- 可将程序分配到不连续的存储区中，在程序运行前只需装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220418231003989.png" alt="image-20220418231003989" style="zoom:50%;" />

# 3. 连续分配方式

`连续分配`：指为用户进程分配的必须是一个`连续的内存空间`。

`内部碎片`: 分配给某进程的内存区域中，如果有些部分没有用上。

`外部碎片`: 是指内存中的某些空闲分区由于太小而难以利用。

## 3.1 单一连续分配

在单一连续分配方式中，内存被分为`系统区`和`用户区`。

- `系统区`通常位于内存的`低地址部分`，用于存放操作系统相关数据；
- `用户区`用于存放用户进程相关数据。内存中只能有一道用户程序，用户程序独占整个用户区空间。
- `优点`：实现简单；`无外部碎片`；可以采用覆盖技术扩充内存；不一定需要采取内存保护（硬件要求低）。
- `缺点`：只能用于单用户、单任务的操作系统中；有`内部碎片`；存储器利用率极低。

## 3.2 固定分区分配

概念：将`整个用户空间`划分为`若干个固定大小的分区`，在每个分区中`只装入一道作业`，可运行多道程序

- `分区大小相等`：缺乏灵活性，但是很适合用于用一台计算机控制多个相同对象的场合（比如：钢铁厂有n个相同的炼钢炉，就可把内存分为n个大小相等的区域存放n个炼钢炉控制程序）
- `分区大小不等`：增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分（比如：划分多个小分区、适量中等分区、少量大分区）

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220418232630135.png" alt="image-20220418232630135" style="zoom:50%;" />

记录内存情况

- 将分区按大小排队，一般由小到大；建立分区使用表, 每个表项包括对应分区的大小、起始地址、状态（是否已分配）
- 程序装入时，由内存分配程序检索分区使用表，找到符合要求的分区，并进行标记
- `优点`：实现简单，`无外部碎片`
- `缺点`：会产生`内部碎片`，内存利用率低； 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能

## 3.3 动态分区分配

`动态分区分配`又称为`可变分区分配`

- 不会预先划分内存分区，而是在进程装入内存时，根据进程的大小`动态`地建立分区；因此系统分区的大小和数目是可变的。
- 动态分区分配没有`内部碎片`，但是有`外部碎片`

`记录内存的使用情况`的数据结构

- 空闲分区表：每个空闲分区对应一个表项。表项中包含分区号、分区大小、分区起始地址等信息
- 空闲分区链(双向指针)：每个分区的起始部分和末尾部分分别设置前向指针和后向指针。起始部分处还可记录分区大小等信息

---

基于顺序的分配算法

- 首次适应算法（效果最好）：

> **算法思想**：每次都从低地址开始查找，找到第一个能满足大小的空闲分区。
>
> **如何实现**：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
>
> 特点：**内存低端会留下小的空闲区，高端有大的空闲区**

- 最佳适应算法

> **算法思想**：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。
>
> **如何实现**：空闲分区**按容量递增次序链接**。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区
>
> **缺点：**每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多的外部碎片。

- 最坏适应算法

> 又称最大适应算法（Largest Fit）
> **算法思想：**为了解决最佳适应算法的问题——即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。
>
> **如何实现：**空闲分区按**容量递减次序链接**。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
>
> 缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了

- 临近适应算法

> **算法思想：**首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
>
> **如何实现**：空闲分区以地址递增的顺序排列（可排成一个循环链表）。每次分配内存时从上次查找结束的位置开始查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。

---

基于索引搜索的分配算法

- 快速适应算法
- 伙伴系统

---

回收

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220418234446406.png" alt="image-20220418234446406" style="zoom:50%;" />

---

分配操作

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419112348290.png" alt="image-20220419112348290" style="zoom:50%;" />

## 3.4 动态可重定位分区分配

概念

![image-20220419105017203](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419105017203.png)

实现

- 必须要`动态重定位`, 和 重定位寄存器的支持（硬件地址变换机构支持实现）
- 重定位寄存器：存放程序在内存中的起始地址

流程

![image-20220419105301532](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419105301532.png)

# 4. 非连续分配方式

CPU的内存管理单元（Memory Management Unit，MMU）负责虚拟地址到物理地址的转换。

此外，还有地址旁路缓存（Translation Lookaside Buffer，TLB）

## 4.1 分页

1. 把内存和我们的程序分为大小相等且固定的一页一页的形式
2. 逻辑上连续的逻辑页在内存中可以分散开来，分配到不相邻的物理页中。
3. 因为逻辑页在内存中是不连续的，所以为了能知道进程的每个页面在内存中存放的位置，我们引入了`页表`的概念。
4. 页表记录`页号`和`物理块号`之间的映射关系。

---

逻辑地址A对应的物理地址= P号页面在内存中的起始地址+页内偏移量W

1. 确定逻辑地址A对应的页号
2. 找到P号页面在内存中的起始地址（需要查页表）
3. 确定逻辑地址A的“页内偏移量

十进制计算

1. 页号=逻辑地址 / 页面长度
2. 页内偏移量=逻辑地址 % 页面长度

二进制计算

1. 页内偏移量：根据页的大小$$2^k$$,则逻辑地址的后k位就是页内偏移量
2. 页号：其余部分就是页号

## 4.2 分段

1. 段式按照程序自身的逻辑关系将程序和主存划分为若干个段，每段的大小可以不等
2. 段表存储着：逻辑段号 + 基址 + 段长
3. 翻译过程中，`MMU`通过`段表基址寄存器`找到段表位置，结合`段号`找到段表中对应段信息，取出该段起始地址（`物理地址`）加上虚拟地址内的`段内地址`（偏移）得到最终的物理地址。
4. 缺点：存在`外部碎片`的问题

分段存储**主要是为了满足用户和程序员的下述需要**

- 方便编程: 
- 信息共享: **共享的实现以是信息的逻辑单位为基础**
- 信息保护: **同样是对逻辑单位进行保护**
- 动态增长: **如数据段**
- 动态链接: **运行时调入内存并链接**

---

**越界访问控制**

- *逻辑地址的段号与段表长度比较；**
- **段内地址与段表中保存的段长比较；*

## 4.3 页表

**页表存放在内存系统区的一个连续空间中**

- PCB 和 页表寄存器PTR 中存有页表在内存的`首地址`和`页表长度`

单级页表存在的问题

- 所有页表项必须连续存放，页表过大很占用内存空间。
- 在一段时间内并非所有的页面都使用到，因此没必要整个页表常驻内存
- 单级页表的每一项必须存在：因为必须是连续存放的，因此地址翻译是根据其虚拟页号找到对应的下标，从而找到对应的页表项

使用多级页表：

1. 64位系统下的4级页表：每个页4KB，最低12位($2^{12}$=4KB)来表示页内偏移。每个页表页也占用物理内存的一个物理页(4KB)，每个页表项8字节，所以一个页表页可以对应512页表项(4KB/8B=512=$2^9$)。所以，48-63位全部置为0或者是1。剩下36+12分别对应四级页表，和页表内偏移量。

2. 32位系统下的2级页表：每个页4KB，最低12位($2^{12}$=4KB)来表示页内偏移。每个页表页也占用物理内存的一个物理页(4KB)，每个页表项4字节，所以一个页表页可以对应1024页表项(4KB/4B=1024=$2^{10}$​)。所以，20+12分别对应二级页表(2*10)，和页表内偏移量
3. 支持按需加载，对于不需要用到的页表可以不加载进内存。

## 4.4 快表(联想寄存器)

1. **出现原因**：操作系统使用多级页表实现了页表的压缩，但是会导致地址翻译时长增加，一次地址翻译导致多次物理内存访问。
2. **出现目的**：为了**减少地址翻译访存次数**，MMU引入地址旁路缓存（Translation Lookaside Buffer，TLB）部件来加速地址翻译过程。
3. **实现原理**：基于程序的局部性原理（时间局部性和空间局部性）
4. **实现流程**：TLB缓存了虚拟页号到物理页号的映射关系。和k-v结构类似，k为虚拟页号，v为物理页号。MMU会先以虚拟页号为key去TLB中查缓存项，TLB命中则直接返回。若未命中，则去查页表后将结果写入到TLB中。
5. **物理结构**：TLB硬件一般采用分层结构，L1部分分为指令TLB与数据TLB，L2不区分指令与数据，`作为CPU内部硬件`。

![image-20220103114946458](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220103114946458.png)

6. **一致性保证**

- 在TLB引入需要保证TLB中内容与当前页表内容的一致性，页表在切换时（应用程序切换）主动刷新TLB。
- 若操作系统在切换程序的过程中刷新TLB，那么应用程序开始执行的时候总是会发生TLB未命中。
- 为了避免这一开销，使用ASID机制。操作系统为每一个应用分配不同的标签，这个标签记录在页表基址寄存器和TLB的缓存项中，从而使得TLB中属于不同应用程序的缓存项就可以被区分开；在切换页表的适合也不需要清空TLB了。

有快表的话：

- 快表命中，只需一次访存
- 快表未命中，需要两次访存

## 4.5 分页和分段的异同

共同点

- 都是非连续分配方式，目的是为了提高内存利用率

区别

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序，可以分卫代码段，数据段等
- 分页产生内部碎片，不会产生外部碎片；分段产生外部碎片，不会产生内部碎片
- 分页的逻辑地址是一维的，分段的逻辑地址是二维的，段页式是三维的

## 4.6 段页式

**分页：有效提高内存利用率**

**分段：很好的满足用户需求**

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210908090850402.png" alt="image-20210908090850402" style="zoom:50%;" />

# 5. 内存空间的扩充

覆盖和交换的区别

- 覆盖是在同一个程序或进程中
- 交换是在不同进程(作业)中

## 5.1 覆盖

覆盖的基本思想如下:

- 由于程序运行时并非任何时候都要访问程序及数据的各个部分(尤其是大程序)，因此可把用户空间分成一个固定区和若干覆盖区。
- 将经常活跃的部分放在固定区，其余部分按调用关系分段。
- 首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。

一个固定区：存放最活跃的程序段，固定区中的程序段在运行过程中不会调入调出

若干覆盖区：需要用到时调入内存，用不到时调出内存

缺点：必须由程序员申明覆盖结构，操作系统完成自动覆盖。对程序员不透明。覆盖技术只用于早期的操作系统中，现在已成为历史。

## 5.2 对换(swap)

`中期调度`：

- 将被调度的进程挂起，并将被挂起的进程所使用的内存页替换到磁盘中(页面置换算法),`限制系统中可被调度的进程`

> 对换区是采用连续分配方式，文件区是采用离散分配方式
>
> 所以对换区的数据存取(磁盘IO)速度比文件区的高

进程的换出：

- **选择处于阻塞状态且优先级最低的进程**
- **将该进程的程序和数据传送到磁盘的对换区上**
- **回收内存空间，修改该进程的****PCB**

进程的换入：

- 定时查看进程状态
- **将处于就绪态的，换出时间最久的进程换入内存**

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210907074705791.png" alt="image-20210907074705791" style="zoom:50%;" />

## 5.3 虚拟存储器

虚拟存储器是指具有 `请求调入功能`和 `置换功能`，能从`逻辑上对内存容量加以扩充`的一种存储器系统

- 必须建立在离散分配的内存管理技术基础上
- **页式虚拟存储系统**： 基本分页系统 + 请求调页功能 + 页面置换功能
- **段式虚拟存储系统**： 基本分段系统 + 请求调页功能 + 页面置换功能

硬件支持：页表，缺页中断，地址变换机构

软件支持：请求调页软件，页面置换软件

特征

- 多次性：作用总的程序和数据允许被分成多次调入内存
- 对换性： 作业运行时无需常驻内存
- 虚拟性：从逻辑上扩充了内存容量，使用户看到的内存容量远大于实际内存容量

---

内存分配策略

- 最小物理块数的确定：保证程序能够正常运行所需的最小物理块数；**与硬件结构有关，取决于指令的格式、功能和寻址方式**
- 物理块的分配策略：
  - 固定分配局部置换：为进程分配的物理块数在运行期间都不再改变。若某个进程发生缺页，则只能将自己的某个内存页换出
  - 可变分配全局置换：为每个进程分配一定数目的物理块，当进程发生缺页，若系统中有空闲的物理块，则分配一个物理块并装入缺页；页面的置换范围是任一个进程。
  - 可变分配局部置换：为每个进程分配一定数目的物理块后，若某个进程发生缺页，则只能将自己的某个内存页换出。OS根据缺页率进行物理块分配的调整。

物理块分配算法

- 平均分配算法：**将空闲物理块，平均分配给各个进程**
- 按比例分配算法：**根据进程的大小按比例分配物理块的**
- 考虑优先权的分配算法：**优先权高的一次分得的物理块数多**

何时调入页面：

- 预调页策略：可以用于首次调入内存时，以及工作集的时候
- 请求调页策略：**运行中的发生缺页现象时**

何处调入页面

- **系统拥有足够的对换区空间**：
- **系统缺少足够的对换区空间**：
- **UNIX方法**

页面调入过程

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419202135248.png" alt="image-20220419202135248" style="zoom:50%;" />

缺页率

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419202233231.png" alt="image-20220419202233231" style="zoom:50%;" />

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210908092730476.png" alt="image-20210908092730476" style="zoom:50%;" />

# 6. 页面置换算法

1. 最佳置换算法(OPT)：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。

> 按最佳置换的规则，往后寻找，最后一个出现的页号就是要淘汰的页面.
>
> <font color="red">无法实现</font>

2. 先进先出置换算法(FIFO)

> Belady: 当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。

3. 最近最久未使用算法(LRU):用`访问字段记录该页面自上次被访问以来所经历的时间t`

> 在手动做题时，若需要淘汰页面，可以逆向检查此时在内存中的几个页面号。<font color="red">在逆向扫描过程中最后一个出现的页号就是要淘汰的页面。</font>
>
> 需要硬件支持
>
> - 寄存器
> - 栈

4. 最少使用置换算法(LFU)

> 选择在最近时期使用最少的页面淘汰

4. Clock置换算法(NRU)

> 将换入物理内存的页号排成时钟的形状**，该时钟有一个钟臂，指向新换入内存的页号的后一个**。同时，也为每一个页号维护一个访问标志位。换出页号时：
>
> - 若有访问标志，标志清空，针臂摆动到下一个页号。
>
> - 若访问位没有设置，该页换出；

4. 页面缓冲置换算法(PBA)

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419203514645.png" alt="image-20220419203514645" style="zoom:50%;" />

5. 改进型的时钟置换算法

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210908103438610.png" alt="image-20210908103438610" style="zoom:50%;" />

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210908101938531.png" alt="image-20210908101938531" style="zoom:50%;" />

# 7. 工作集 与 抖动

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220419203618588.png" alt="image-20220419203618588" style="zoom:50%;" />

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20210908104812158.png" alt="image-20210908104812158" style="zoom: 80%;" />

1. **出现原因**：选择的替换策略如果和实际工作负载不匹配，导致最近使用的内存页刚换出又换入，可能出现颠簸（thrashing）现象，造成严重的性能损失。

> 比如对一个有良好局部性的场景使用MRU策略，导致**最近使用的内存页刚换出又换入**，CPU的大部分时间用来处理缺页异常和等待磁盘操作。而系统的调度器可能会加剧颠簸现象，因为长时间等待磁盘操作，CPU利用率下降，为了提高利用率，调度器载入更多应用程序加剧缺页异常，进一步降低CPU利用率。

2. **工作集定义**：一个应用程序在时刻t的工作集W为它在时间区间[ t - x , t ]使用的内存页集合，也被视为它在未来（下一段x时间内）会访问的内存页集合，换出时，优先将非工作集的页换出
3. **工作集算法**：`工作集时钟算法`

- 每隔固定事件，调用一个工作集函数，检查每个页的状态
- 如果访问位为1(表示在时间间隔内被访问)，将访问位清零，然后记录当前系统时间
- 如果访问位为0(时间间隔内没被访问)，将当前时间 - 上次访问时间，如果大于系统设置值，则该页不在属于工作集

