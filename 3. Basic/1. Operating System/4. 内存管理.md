# 1. 为什么要引入虚拟内存

没有虚拟内存的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

- 不安全性：用户可以访问任意内存，容易造成OS的破坏 或者 数据的不安全性
- 不透明性：程序员编写代码是以物理内存基础的，所以需要考虑内存的大小，代码的存放位置，和其他程序的配合等
- 并发度不高：可能存在一个程序覆盖另一个程序的情况，造成程序的崩溃

# 2. 虚拟内存是什么

1. 在应用程序和物理内存之间加上一个新的抽象：虚拟内存。
2. 应用程序在运行时只能使用虚拟地址，操作系统负责设置虚拟地址与物理地址之间的映射（分页还是分段），CPU中的MMU负责将虚拟地址翻译为物理地址
3. 如此使得**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。

虚拟内存的优点

- 高效性：他将主存看做是磁盘的高速缓存，根据按需加载，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。
- 安全性：使应用之间的内存相互隔离，一个应用程序只能访问属于自己的物理内存区域
- 透明性：虚拟内存抽象对程序员透明，开发者无需考虑虚拟内存抽象。

# 3. 虚拟内存是如何运作的

1. `地址翻译`：操作系统通过MMU将虚拟地址转化为物理地址，然后通过物理地址来访问内存。
2. 虚拟内存基于局部性原理。程序在运行的时候不会全部装入内存当中，而是`按需加载`，同时当内存不够的时候，会适当的换出一些数据。

1. `请求调页`:具体的就是当我们访问的信息不在内存中时，由操作系统将信息从外存中调入内存。
2. `页面置换`：当内存空间不够时，将内存中暂时用不到的信息换出外存

## 3.1 地址翻译

CPU的内存管理单元（Memory Management Unit，MMU）负责虚拟地址到物理地址的转换，此外，还有地址旁路缓存（Translation Lookaside Buffer，TLB）

### 3.1.1 分段

1. 段式按照程序自身的逻辑关系将程序和主存划分为若干个段，每段的大小可以不等
2. 段表存储着：逻辑段号 + 物理段号 + 段长
3. 翻译过程中，`MMU`通过`段表基址寄存器`找到段表位置，结合`段号`找到段表中对应段信息，取出该段起始地址（`物理地址`）加上虚拟地址内的`段内地址`（偏移）得到最终的物理地址。
4. 缺点：存在`外部碎片`的问题

### 3.1.2 分页

1. 把内存和我们的程序分为大小相等且固定的一页一页的形式
2. 逻辑上连续的逻辑页在内存中可以分散开来，分配到不相邻的物理页中。
3. 因为逻辑页在内存中是不连续的，所以为了能知道进程的每个页面在内存中存放的位置，我们引入了`页表`的概念。
4. 页表记录`进程页面`和`实际存放的内存块`之间的映射关系。

### 3.1.3 多级页表

**出现原因**：单级页表存在的问题

- 所有页表项必须连续存放，页表过大很占用内存空间。
- 在一段时间内并非所有的页面都使用到，因此没必要整个页表常驻内存

使用多级页表： 

1. 64位系统下的4级页表：每个页4KB，最低12位($2^{12}$=4KB)来表示页内偏移。每个页表页也占用物理内存的一个物理页(4KB)，每个页表项8字节，所以一个页表页可以对应512页表项(4KB/8B=512=$2^9$)。所以，48-63位全部置为0或者是1。剩下36+12分别对应四级页表，和页表内偏移量。

2. 32位系统下的2级页表：每个页4KB，最低12位($2^{12}$=4KB)来表示页内偏移。每个页表页也占用物理内存的一个物理页(4KB)，每个页表项4字节，所以一个页表页可以对应1024页表项(4KB/4B=1024=$2^{10}$​)。所以，20+12分别对应二级页表(2*10)，和页表内偏移量
3. 支持按需加载，对于不需要用到的页表可以不加载进内存。

---

单级页表的每一项必须存在：

- 单级页表必须是连续存放的，因为地址翻译是根据其虚拟页号找到对应的下标，从而找到对应的页表项的

### 3.1.4 TLB

1. **出现原因**：操作系统使用多级页表实现了页表的压缩，但是会导致地址翻译时长增加，一次地址翻译导致多次物理内存访问。
2. **出现目的**：为了**减少地址翻译访存次数**，MMU引入地址旁路缓存（Translation Lookaside Buffer，TLB）部件来加速地址翻译过程。
3. **实现原理**：基于程序的局部性原理（时间局部性和空间局部性）
4. **实现流程**：TLB缓存了虚拟页号到物理页号的映射关系。和k-v结构类似，k为虚拟页号，v为物理页号。MMU会先以虚拟页号为key去TLB中查缓存项，TLB命中则直接返回。若未命中，则去查页表后将结果写入到TLB中。
5. **物理结构**：TLB硬件一般采用分层结构，L1部分分为指令TLB与数据TLB，L2不区分指令与数据，`作为CPU内部硬件`。

![image-20220103114946458](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220103114946458.png)

6. **一致性保证**

- 在TLB引入需要保证TLB中内容与当前页表内容的一致性，页表在切换时（应用程序切换）主动刷新TLB。
- 若操作系统在切换程序的过程中刷新TLB，那么应用程序开始执行的时候总是会发生TLB未命中。
- 为了避免这一开销，使用ASID机制。操作系统为每一个应用分配不同的标签，这个标签记录在页表基址寄存器和TLB的缓存项中，从而使得TLB中属于不同应用程序的缓存项就可以被区分开；在切换页表的适合也不需要清空TLB了。

### 3.1.5 分页和分段的异同

1. 共同点

   - 都是非连续分配方式，目的是为了提高内存利用率
2. 区别

   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序，可以分卫代码段，数据段等
   - 分页产生内部碎片，不会产生外部碎片；分段产生外部碎片，不会产生内部碎片

## 3.2 请求调页

1. **出现原因**：虚拟内存基于局部性原理。程序在运行的时候不会全部装入内存当中，而是`按需加载`，所以存在应用程序访问**已分配但未映射至物理内存的虚拟页**
2. **解决手段**：应用程序访问**已分配但未映射至物理内存的虚拟页**，就会触发`缺页异常`。此时CPU会运行操作系统预先设置的缺页异常处理函数（page fault handler），该函数找到（或换页）一个空闲的物理页，将写到磁盘上的数据重新加载到该物理页中，并且在页表中填写虚拟地址到这以物理页的映射。该过程称为换入（swap in）。

3. **优化**：缺页异常会导致访问延迟增加，操作系统往往会引入`预取（prefetching）`机制进行优化。`基于程序局部性原理`，当发生缺页异常时，将临近的虚拟页也进行映射，从而减少缺页异常的次数，提高程序的性能。
4. **优点**：这种按需分配的机制使得操作系统能够在应用程序真正需要使用物理内存的适合再分配物理页，因而能够有效节约物理内存，提高资源利用率

## 3.3 页面置换

1. **出现场景**：操作系统会**在物理内存容量不足时把若干物理页写到类似于磁盘这种容量更大更便宜的储存设备中，然后就可以回收这些物理页并继续使用**。
2. **优化**：**基于程序局部性原理**，当换入时，猜测还有哪些页会被访问，提前换入内存，减少缺页此数。

3. **优点**：能够为应用程序提供超过物理内存容量的内存空间。
4. 页面置换算法：

- `MIN/OPT`（Minimum，Optimal）：优先选择未来不会访问的页，或者是在最长时间内不再被访问的页面。该算法无法实现.

- `FIFO`（First-In First-Out）：维护一个先进先出的队列，总是淘汰最先进入内存的页面,时间开销低，但是实际表现不佳，先后顺序和使用频繁关系与否不大。

- `Second Chance`：维护一个先进先出的队列，为每一个物理页号维护一个访问标志，访问了就置上访问标志位；每次将换出时，按照FIFO的逻辑，如果有标志，则标志清零，并移到队尾；如果没有标志，则会被换出。当所有标志失效时，弱化为FIFO。

- `LRU`（Least Recently Used）：被换出时，优先选择最久未被访问到的，维护一个链表，按照尾插法，链表尾放最常用的，首端放最不常用的，每次淘汰首端。

- `MRU`（Most Recently Used）：用LRU相反的策略，优先换出最近访问的页面，基于假设“程序不会反复访问相同的地址”。

- `Clock Algorithm`：将换入物理内存的页号排成时钟的形状**，该时钟有一个钟臂，指向新换入内存的页号的后一个**。同时，也为每一个页号维护一个访问标志位。换出页号时：

  - 若有访问标志，标志清空，针臂摆动到下一个页号。

  - 若访问位没有设置，该页换出；

# 4. 工作集模型

1. **出现原因**：选择的替换策略如果和实际工作负载不匹配，导致最近使用的内存页刚换出又换入，可能出现颠簸（thrashing）现象，造成严重的性能损失。

> 比如对一个有良好局部性的场景使用MRU策略，导致**最近使用的内存页刚换出又换入**，CPU的大部分时间用来处理缺页异常和等待磁盘操作。而系统的调度器可能会加剧颠簸现象，因为长时间等待磁盘操作，CPU利用率下降，为了提高利用率，调度器载入更多应用程序加剧缺页异常，进一步降低CPU利用率。

2. **工作集定义**：一个应用程序在时刻t的工作集W为它在时间区间[ t - x , t ]使用的内存页集合，也被视为它在未来（下一段x时间内）会访问的内存页集合，换出时，优先将非工作集的页换出
5. **工作集算法**：`工作集时钟算法`

- 每隔固定事件，调用一个工作集函数，检查每个页的状态
- 如果访问位为1(表示在时间间隔内被访问)，将访问位清零，然后记录当前系统时间
- 如果访问位为0(时间间隔内没被访问)，将当前时间 - 上次访问时间，如果大于系统设置值，则该页不在属于工作集

# 5. 虚拟内存功能

1. 共享内存

- 两个程序的虚拟地址映射到同一物理地址
- 可以用于进程间的通信

2. 写时拷贝，COW

- 允许多个进程以只读的方式共享同一个物理内存，一旦某个进程要进行修改，则会触发缺页异常
- 缺页异常函数会将该物理页拷贝一份，以可读可写的方式映射给对应进程
- 作用：节省内存资源，防止在fork时发生大量的拷贝，造成性能 和 空间的损耗

3. 内存去重，KSM（Kernel Same-page Merging）

- OS定期扫描具有相同内容的物理页，然后只保留其中一个物理页，将其他物理页的对应逻辑页映射到同一个物理页
- 其中该物理页被标记为只读，写时拷贝的

4. 内存压缩,zswap

- 内存资源不足时，操作系统**选择一些“最近不太会使用”的内存，压缩其中的数据**，释放出空闲内存。要用时，操作系统解压即可。

- 所有的操作都**在内存中进行**，比换出内存到磁盘上更迅速。

- 大页

- **出现原因**：大页机制是用来缓解TLB缓存项不够用的问题。

-  **思想**：大页的大小可以是2MB甚至是1GB，使用大页可以大幅度地减少TLB占用量。

- **好处**：可以**减少TLB缓存项的使用，提高TLB命中率**，另一方面**减少页表级数，提升查询页表的效率**。

- **缺点**：程序**未使用整个大页导致内存资源浪费**，**增加操作系统管理内存的复杂度**使产生漏洞。

# 6. 物理内存分配器(ToDo)

一个优秀的物理内存分配器需要兼顾内存资源利用和性能

## 6.1 buddy system

### 6.1.1 思想

伙伴系统（buddy system）在现代操作系统中被广泛地用于分配连续的物理内存页。其基本思想是将物理内存划分成连续的块，**以块为基本单位进行分配**。不同的快大小可以不同，但每个块都由一个或多个连续的物理页组成，物理页的数量必须为2的n次幂。

当一个请求需要分配m个物理页时，伙伴系统寻找一个合适的块，包含$2^n$个物理页的块，满足 $2^{n-1}$ < m ≤ $2^n$。

在处理分配请求时，大的块可以分裂成两个小一号的块，互为伙伴，分裂所得块可以**持续分裂直到满足分配请求**。

在一个块被释放后，分配器找到其伙伴块，若伙伴块同样空闲，则**合并成更大的空闲块尝试继续合并**。

由于分裂和合并操作都是级联的，能够很好的缓解外部碎片。

### 6.1.2 数据结构---空闲链表

## 6.2 SLAB

# 7. 其他

**内存管理提供的功能：**

1. `存储保护`: 保证各进程在自己的的内存空间运行，不会越界访问

2. `地址转换`: 操作系统负责将逻辑地址转化为物理地址，实现方式就是`内存装入`的三种方式

3. `内存空间的扩充`: 利用覆盖技术，交换技术，虚拟存储技术实现,从逻辑上扩充内存

4. `内存空间的分配与回收`: 由操作系统完成内存空间的分配和管理，对程序员透明

Intel使用段页式加上页式管理。

Linux使用页式管理。

> 1. 但是因为CPU的硬件结构必须先段式映射，再进行页式映射
> 2. Linux就将每个段都是从0地址开始然后占据整个虚拟空间

