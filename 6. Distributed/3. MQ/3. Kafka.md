# Main Concepts

## Definition

1. Kafka的定义:

- 传统定义：`分布式`的 基于 `发布 / 订阅` 模式 的 `消息队列`
- 最新定义：`分布式事件流平台(Event Streaming Platform)`

2. 流处理平台所需具备的能力:

- 消息队列: 发布和订阅 streams of events
- 存储系统: 持久化 和 容错 的存储 streams of events
- 流处理平台: 处理 streams of events 的能力

3. Kafka四大核心API:

- Producer API: 发布消息到1个或多个topic中
- Consumer API: 订阅一个或多个topic，并处理产生的消息
- Streams API: 允许应用 从 topic 中消费输入流, 并产生输出流到 topic 中
- Connector API: 构建或运行可重用的生产者或消费者,将topic连接到现有的application或DB.如,连接到关系数据库的连接器可以捕获表的每个变更

## Terminology

![Kafka Topics](https://static.javatpoint.com/tutorial/kafka/images/kafka-topics-2.png)

1. Broker

- 运行 Kafka 的服务器, 包含一系列 topics
- 连接到其中一个 Broker就相当于连接到整个 cluster

2. Topic: 

- topic 类似与文件夹, message 类似于文件
- topic 可以有 n 个 Producer 发布, n 个 Consumer 订阅

3. Partition

- 为方便拓展，以及提高`并发度`，一个topic可以分为多个partition, 从而分布在不同的 Broker
- partition 是一个有序的队列，给定 partition 的任意 consumer 都会按照 event 写入顺序进行读取
- Partition 在存储层面可以看作是一个可追加的日志文件

4. Message / record / event

- 组成：key，vaule，timestamp，optional metadata headers
- 在被消费后，Message并不会被删除，而是保存直到他们过期

## Replication

1. Leader and Follower：多副本机制

- 起因: 为了提高 fault-tolerant，为每个 partition 增加若干 replica, replica 的个数由 replication factor决定(通常为 3)
- Leader: 生产者发送数据的对象，以及消费者消费数据的对象都是 leader
- Follower: 只负责与 leader 副本的消息同步; leader 发生故障时，某个 follower 会成为新的 leader
- 分区中的所有副本统称为AR(Assigned Replicas); 与leader保持一定同步的称之为ISR(In-Sync Replicas，包括leader); 与leader同步滞后过多的副本(不包括leader)组成OSR。AR = ISR + OSR 

2. HW 和 LEO: 复制策略

- HW: High Watermark，用来标识某一特定的offset，消费者只可以拉取到这个offset之前的消息
- LEO: Log End Offset，标识当前日志文件中下一条待写入消息的offset
- 每个 partition 的 ISR 集合中的每个 replica 都会维护自身的 LEO, 而 ISR 集合中最小的LEO即为分区的HW
- 比同步复制性能好，同时避免了异步复制存在的数据丢失问题

3. Leader 选举: TODO

## Delivery semantics

1. 传递语义:

- At most once(基本不使用): 消息可能会丢失，但绝不会被重复消费
- At least once: 消息不会丢失, 但可能重复消费 --> 默认提供
- Exactly once: 消息不会丢失，也不会被重复消费 --> 通过幂等 + 事务实现(将offset 的修改 以及处理数据使用同一个事务)

2. Producer 角度:

- 消息丢失: ack = 0 消息会丢失; ack = 1 和 ack = all, 消息不会丢失

```java
// Java 解决方案
// 1. 开启 ack =1 | ack = all
// 2. 设置重试次数
```

- 消息重复: 开启了幂等传递就不会重复发送(broker为每个 Producer 分配一个ID，并通过生产者发送的序列号为每个消息进行去重)

```java
// 1. 开启幂等传递
```

3. Consumer 角度:

- 消息丢失: 消费者保存了 offset, 但是在处理数据前 crash 了; Rebalance 后会丢失那部分数据

```java
// 1. 关闭自动提交, 转而使用手动提交 offset
```

- 消息重复: 消费者处理了数据, 但是在保存 offse之前 crash 了; Rebalance 后会重复处理

```java
// 1. 关闭自动提交, 然后做幂等校验, 比如 Redis 的set、MySQL 的主键等天然的幂等功能
```

# Producer

> Producer是线程安全的, 线程之间共享单个生产者, 通常比多个Producer实例要快

## Configuration

```java
Properties props = new Properties();
// Kafka Broker 地址列表
props.put("bootstrap.servers", "localhost:9092");
// 收到多少 ack 才认为请求完成, 从而生产者继续运行 (对应持久化机制)
// - acks = 0: Producer 发完就认为请求完成; `retries参数会失效`; 返回的 offset永远为-1
// - acks = 1: Leader 持久化数据以后 认为请求完成
// - acks = all(-1): Leader 和 所有 Follower 持久化数据以后认为请求完
props.put("acks", "all");
// 重试次数
props.put("retries", 0);
// Producer 在内存中为每个分区维护了一个 buffer, 其大小由 batch.size 确定, 用来存放未发送的数据
// 将数据打包发送的条件: 1. 数据的大小达到了 batch.size 2. 等待的时间超过了 linger.ms
props.put("linger.ms", 1);
props.put("batch.size", 16384);
// Producer 用来缓存 record 的内存总字节数, 如果满了就会等待max.block.ms(用于清空 buffer), 然后抛出异常
props.put("buffer.memory", 33554432);
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
```

## Send Message

Producer 发送数据: send 方法

- 异步: send 方法本身是异步的, 当将 record 存储到buffer 后就会立即返回(Producer 的 IO 线程负责将 record 发送给 cluster)
- 返回值: Future<RecordMetadata>, RecordMetadata包含了record 被放到哪个 topic, partition, offset
- 回调: 当收到 ack 后会调用提供的 Callback (也可以不提供, Producer 的 IO 线程执行这个 Callback)

```java
// 具有相同 key 的 Message 会被写入到相同的 Partition 中去
ProducerRecord<String,String> record = new ProducerRecord<String,String>(
  "topic","key","value"
);
// 异步发送, 不管结果
producer.send(new ProducerRecord<String, String>("topic","key","value");
// 异步发送, 回调获取结果
producer.send(record,new MyProducerCallback());
// 使用 get 进行 同步阻塞
RecordMetadata result = producer.send(record).get();        
```

负载均衡:

- 固定 Partition: 如果指定了 Key 或者设计了 Partition Function
- 随机 Partition: 都没指定则按照随机策略

自定义分区器: (TODO)

## idempotence & transactional

幂等生产者(idempotence)

- 启用: 将 `enable.idempotence` 配置设置为true, 之后 `retries（重试` 配置将默认为 Integer.MAX_VALUE，`acks` 配置将默认为 all
- 作用: 精准一次交付, 保证单个会话内发送的消息的幂等性(不丢失, 不重复)

事务生产者(transactional)

- 启用: TODO
- 作用:  Producer 原子地将消息发送到多个分区



# Consumer

## Consumer Group

1. 消费者组: 相同 group.id 的 Consumer 为一组

- 消费者组 逻辑上可以理解为单个订阅者, 只不过这个订阅由多个进程组成
- 分区有序性: 组内每个消费者并行消费，一个partition只能由一个组内消费者消费，并按顺序消费数据
- 一个 partition 可以被多个消费者组订阅

2. Rebalance:

- 本质: 消费者组中消费者的数量 或者 订阅的 Topic 中 Partition 的数量发生变化
- 解决: 重新分配 Partition 和 Consumer 之间的关系
- 优点: 提升消息的并行消费能力
- 缺点: 可能导致消息重复(因为Consumer 默认是异步提交); 同时也会导致消费暂停(Rebalance 完成前需要暂停部分 Partition 的消费)

## offset

1. Consumer 中有两种 offset:

- 第一种: 表示对应 Partition 中第一个未被消费的 record 的位置; 每次调用 `poll()`都会自增

```java
Long position(TopicPartition partition)
```

- 第二种: 表示已经被安全存储的最大 offset (被存储在 Broker 的`__consumer_offsets`这个Topic, 具体 Partition 由 groupid 决定) 
- 其中第二种的作用在于当发生 Rebalance时, 新的 Conusmer 能够继续之前的工作

```java
// 调用commitSync() | commitAsync进行同步, 提交的是poll()返回的 offset, 所以需要处理完 poll返回的消息之后调用
commitSync();
commitAsync();
```

2. 自动提交: 

- 在 poll()里进行, 每次 poll 时会首先检测是否进行提交, 然后再进行数据的拉取

- 当 Rebalance 时可能会发生重复消费, 消息丢失的情况

```java
// 开启自动提交
props.setProperty("enable.auto.commit", "true");
// 提交偏移量的时间间隔
props.setProperty("auto.commit.interval.ms", "1000");
```

3. 同步提交: 

- 当 Rebalance 时还是可能会发生重复消费

```java
// 关闭自动提交
props.put("enable.auto.commit", false);
// 业务处理结束执行
try {
    // 用commitSync()提交由poll方法返回的最新偏移量，会阻塞直到提交完成
    consumer.commitSync();
} catch (CommitFailedException e) {
    System.out.println(e.getMessage());
} finally { 
  consumer.commitSync();
}

```

4. 同步异步提交: **推荐使用**

```java
props.setProperty("enable.auto.commit", "false");
try {
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(200));
        for (ConsumerRecord<String, String> record : records) {
            System.out.printf("offset = %d, key = %s, value = %s\n", record.offset(), record.key(), record.value());
        }
        // 异步提交
        consumer.commitAsync(new OffsetCommitCallback() {
            @Override
            public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception e) {
                if (e != null) {
                    LOG.error("Commit failed for offsets {}", offsets, e);
                }
            }
        });
    }
} catch (Exception e) {
    LOG.error("consumer error", e);
} finally {
    try {
        // 同步提交
        consumer.commitSync();
    } finally {
        consumer.close();
    }
}
```

## Transactional Messages

对于事务消息, Consumer应该被配置为只读取已提交的数据

- 设置`isolation.level=read_committed`

> TODO

## Push vs. Pull

> Kafka 的消息推送方式是 长轮训

1. Kafka 基于 Pull 模式

- 每次 Pull 请求会指定要消费的 Partition 的 offset
- Broker 会返回以该 offset 为起始位置的一块数据
- 长轮训: 基于 NIO 的 select, 

2. Kafka 的长轮训:

- 传统的 Poll 存在的缺点: 当 Broker 中没有数据的时候, Consumer 会陷入不断 loop, 直到数据到来(类似于 IO 中的同步非阻塞)
- 长轮训: 基于 NIO 的 select阻塞, 只有满足一定条件才进行返回, 如消息达到一定规模(类似于 IO 多路复用)

3. 控制 poll 循环的参数

- `max.poll.interval.ms`：设置 poll 的间隔
- `max.poll.records`: 限制每次调用poll返回的消息数

# Stream

```java
Map<String, Object> props = new HashMap<>();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "my-stream-processing-application");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(StreamsConfig.KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
props.put(StreamsConfig.VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
StreamsConfig config = new StreamsConfig(props);

KStreamBuilder builder = new KStreamBuilder();
builder.stream("my-input-topic").mapValues(value -> value.length().toString()).to("my-output-topic");

KafkaStreams streams = new KafkaStreams(builder, config);
streams.start();
```

# Persistence

## Storage Structure

1. Kafka 为什么基于文件系统存储数据而不是内存:

- 对磁盘的线性读有些情况比内存随机访问要快 --> Kafka采用磁盘顺序读写的策略(append only)
- 使用 PageCache 进行数据缓存 --> 如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用
- JVM创建对象开销大 且 内存回收在数据量大的情况下慢 --> Kafka 要求高吞吐,低延迟 不适合内存方案

2. Kafka 的设计思路:  

- 建立在在 O(1) 读 和 append 写上面, 类似于日志系统

3. Kafka 设计的优点:

- 无需任何性能损失就可以访问几乎无限制的磁盘空间
- 消息被消费后不是立马被删除，而是可以保存较长的一段时间

4. 存储结构

- 一个 topic 分为多个 partition
- 一个 partition 分为多个 segment
- 一个 segment 对应 .log 文件 和 .index 文件
- 其中消息会不断被追加到log文件末尾
- 同时为了加快访问速度，使用.index文件保存大量的索引信息，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址

5. .index 和 .log文件所在的文件夹

- 该文件夹的命名规则为：topic 名称+分区序号
- index 和 log 文件以当前 segment 的第一条消息的 offset 命名

## Log Compaction

# SpringBoot

# Source Code

