## 0. Introduction

分布式系统的核心：是通过网络使一群计算机相互通信来完成一些连贯的任务

使用分布式的驱动力有

- `性能`：大量的计算机意味着大量的并行运算，大量CPU、大量内存、以及大量磁盘在并行的运行
- `容错`：比如两台计算机运行完全相同的任务，其中一台发生故障，可以切换到另一台
- 有些问题天然是分布式的；或者 为了安全目标

`可扩展性`：如果我用一台计算机解决了一些问题，当我买了第二台计算机，我只需要一半的时间就可以解决这些问题

`可用性`：在特定的错误类型下，系统仍然能够正常运行，仍然可以像没有出现错误一样，为你提供完整的服务

`一致性`：



# 1. Programming Model

`Map`：由用户所编写的**Map**函数接收输入，并生成一个中间键值对集合。MapReduce这个库会将所有共用一个键的值组合在一起，并将它们传递给**Reduce**函数。

`Reduce`:接受一个中间键以及该键的值的集合作为输入; 将这些值合并在一起

# 2. Implementation

## 2.1 Execution Overview

> Master保存了每个Map任务和每个Reduce任务的状态（闲置，正在运行，以及完成），以及非空闲任务的worker机器的ID

1. MapReduce库 将 输入文件 切分为 M个片段； 在集群中启动多个程序副本，其中包含一个master 和 多个 worker
2. master会对worker进行任务分配，包括M个Map任务 和 R个Reduce任务；每个空闲的worker被分配一个map任务或者一个reduce任务。
3. 被分配了map任务的worker会读取相关的输入数据片段，并从输入数据中解析出键值对，并将它们传入用户定义的Map函数中； Map函数所生成的中间键值对(emit)会被缓存在内存中
4. 每隔一段时间，被缓存的键值对会被写入到本地硬盘，并通过`分区函数`分到R个区域内。这些被缓存的键值对在本地磁盘的位置会被传回master。master负责将这些位置转发给执行reduce操作的worker
5. 当reduce知道这些位置以后，该worker就会使用RPC的方式去读取数据。读完以后，根据中间键进行排序
6. reduce worker会对排序后的中间数据进行遍历，对于遇到的每个唯一的中间键，reduce worker会将该key和对应的中间value的集合传入用户所提供的Reduce函数中。Reduce函数生成的输出会被追加到这个reduce分区的输出文件中(Google文件集群服务器的一个文件中)
7. 当所有的map任务和reduce任务完成后，master会唤醒用户程序。此时，用户程序会结束对MapReduce的调用

在成功完成任务后，MapReduce的输出结果会存放在R个输出文件中（每个reduce任务都会生成对应的文件，文件名由用户指定）。一般情况下，用户无需将这些文件合并为一个文件。他们通常会将这些文件作为输入传入另一个MapReduce调用中。或者在另一个可以处理这些多个分割文件的分布式应用中使用

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/v2-5642ac8d1e37098be1c97836341a7210_1440w.jpg" alt="img" style="zoom:50%;" />

## 2.2 Fault Tolerance

### 2.2.1 Worker Failure

**如何判断Worker Failure：**

- Master会周期性ping下每个worker
- 如果在一定时间内无法收到来自某个worker的响应，那么master就会将该worker标记为failed
- 在一台故障的worker上正在执行的任何Map任务或者Reduce任务也会被设置为空闲状态，并等待重新调度

**如果对应的Map任务未完成**

- 如果执行Map的workerA故障了，之后交由worker B来执行
- 所有执行Reduce任务的woker就会接受到这个重新执行的通知
- 任何还没有从worker A中读取数据的Reduce任务将从worker B中读取数据

**如果任务已经完成，那么是否还需重新执行呢**

- 由于已经完成的Map任务的输出结果已经保存在该worker的硬盘中了，并且该worker已经无法访问，所以该输出也无法访问，所以必须重新执行
- 已经完成的Reduce任务则无需再执行，因为它们的输出结果已经存储在全局文件系统中了

### 2.2.2 Master Failure

方法一：

- 让master周期性的将上文所描述的数据结构写入磁盘，即checkpoint
- 如果这个master挂掉了，那么就可以从最新的checkpoint创建出一个新的备份，并启动master进程

方法二：

- 如果只有一个master，所以我们并不希望它发生故障
- 因此如果master故障了，我们目前的实现会中断MapReduce计算
- 客户端可以检查该master的状态，并且根据需要可以重新执行MapReduce操作

### 2.2.3 Semantics in the Presence of Failures（ToDo）

`确定性函数的语义`：当用户提供的map和reduce运算符是确定性函数时，我们所实现的分布式系统在任何情况下的输出都和所有程序在没有任何错误、并且按照顺序生成的输出是一样的

`确定性函数语义的实现`：

- 这种强保证是由Map和Reduce中的commit操作的原子性来保证的
- 每个 in-progress task 都将其输出写进私有临时文件中。每个reduce产生一个私有临时文件，每个map产生R个私有临时文件
- 当map任务完成，map worker发送给master的是那R个临时文件的名称，master在收到消息后，就将这R个文件名记录在自己的数据结构中。如果这个时候由于某些错误，master又收到一遍“我做完了”，master将会忽略
- 当Reduce任务完成时，reduce worker会以原子的方式将临时输出文件重命名为最终输出文件。如果多台机器执行同一个reduce任务，那么对同一个输出文件会进行多次重命名。我们依赖于底层文件系统所提供的原子性重命名操作来保证最终的文件系统状态仅包含一个Reduce任务所产生的数据。

` 非确定性函数的语义`: 提供一种稍弱但依旧合理的语义

## 2.3 Locality

> 网络带宽是在云计算环境中比较稀缺的资源

- GFS 将每个文件分成 64 MB的块，然后将每块保存几个副本（通常为3份）在不同的机器上
- MapReduce的master在调度Map任务时会考虑输入数据文件的位置信息。尽量在包含该相关输入数据的拷贝的机器上执行Map任务

## 2.4 Task Granularity

理想状况下，M和R应当比worker数目大很多，这样才能提高集群的动态负载均衡能力，并且能加快故障恢复的速度，原因是失效的worker上执行的map任务可以分布到所有其他的worker机器上执行。

但是M和R也是有限制的，这一部分限制主要是由于master需要执行O(M+R)次调度。

- 在实际场景中，会使用合适的M值，这样可以让每个map任务中的输入数据大小在16MB到64MB之间
- 将R设置为我们想要使用的worker机器数量的倍数

> 在MapReduce计算中，我们常用的M大小为200000，R为5000，用到的worker机器数量为2000

## 2.5 Backup Tasks

长尾分布现象（或者说“水桶效应”）在MapReduce中也有体现，因为MapReduce计算时间往往取决于其运行速度最慢的worker。

有一个办法来减少“straggler”（落伍的人），master会在任务快完成时，调用backup进程来解决那些 in-progress 任务。这样，无论是原来的进程还是 backup 进程中的哪个先完成，master都立即将其标记为完成。

# 3. Refinements

1. `Partitioning Function`: 默认使用hash函数，但是也可以自定义
2. `Ordering Guarantees`: 在给定的分区中，我们保证中间键值对的处理顺序是根据key的大小进行升序排列
3. `Combiner Function`: 

- 某些任务的中间结果在从map传输到reduce的时候可以先处理一下再传, 比如word count应用, 从而减低网络带宽
- Combiner函数会在每台执行Map任务的机器上执行一次，通常情况下，Combiner函数和Reduce函数的实现代码是一样的
- 唯一的区别在于：Combine 输出是到中间值文件中； reduce 输出到一个最终的输出文件中

4. `Input and Output Types`

- 用户可以通过实现 `reader` 接口来实现自己的输入类型，尽管大多数用户都只使用预定义的类型。

5. `Side-effects`

- 程序员在写Map和Reduce操作的时候，可能会出于方便，定义很多额外功能，比如生成辅助文件等
- 但应当时刻记住，Map和Reduce操作应当保证原子性和幂等性
- 对于一个任务产生了多个输出文件的这种情况，我们并没有为两段提交提供原子性的支持，因此，生成多个输出文件并且具有跨文件一致性需求的任务应当具有确定性

6. `Skipping Bad Records`

- 每个worker进程都会通过一个handler来捕获内存段异常（segmentation violation）和总线错误（bus error）
- 在调用用户的Map或Reduce操作前，MapReduce库会用一个全局变量来保存参数序号
- 如果用户代码产生了一个signal，singnal handler就会在发送一个UDP包时，在该UDP包中放入该序号并发送给MapReduce master
- 当master检测到在某条记录上有多次故障的时候，当它发出相应的Map或者Reduce任务重新执行时，就会指示应该跳过这条记录

7. `Counters`

```go
Count* uppercase;
uppercase = GetCounter("uppercase");

map(String name, String contents) :
    for each word w in contents:
        if(isCapitalized(w)):
            uppercase->Increment();
        EmitIntermediate(w,"1");
```

> shuffle：将所有具有相同 key 的value 发送个单个的 reduce 进程，在网络上传输数据，是MapReduce代价最大的部分

# 4. Word Frequency

```C++
#include "mapreduce/mapreduce.h"
// User’s map function 
class WordCounter : public Mapper { 
    public: virtual void Map(const MapInput& input) { 
        const string& text = input.value(); 
      	const int n = text.size(); 
      	for (int i = 0; i < n; ) { 
            // Skip past leading whitespace 
            while ((i < n) && isspace(text[i])) 
               i++;
            // Find word end 
            int start = i; 
            while ((i < n) && !isspace(text[i]))
               i++;
            if (start < i) 
               Emit(text.substr(start,i-start),"1");
        }
    }
};   


REGISTER_MAPPER(WordCounter);
// User’s reduce function 
class Adder : public Reducer { 
    virtual void Reduce(ReduceInput* input) { 
        // Iterate over all entries with the 
        // same key and add the values 
        int64 value = 0; 
        while (!input->done()) { 
            value += StringToInt(input->value()); 
            input->NextValue();
        }
        // Emit sum for input->key() 
        Emit(IntToString(value));
    }
};

REGISTER_REDUCER(Adder);
int main(int argc, char** argv) { 
    ParseCommandLineFlags(argc, argv);
    MapReduceSpecification spec;
    // Store list of input files into "spec" 
    for (int i = 1; i < argc; i++) { 
        MapReduceInput* input = spec.add_input(); 
        input->set_format("text"); 
        input->set_filepattern(argv[i]); 
        input->set_mapper_class("WordCounter");
    }
    // Specify the output files: 
    // /gfs/test/freq-00000-of-00100 
    // /gfs/test/freq-00001-of-00100 
    // ... 
    MapReduceOutput* out = spec.output();
    out->set_filebase("/gfs/test/freq"); 
    out->set_num_tasks(100); 
    out->set_format("text"); 
    out->set_reducer_class("Adder");
    // Optional: do partial sums within map 
    // tasks to save network bandwidth 
    out->set_combiner_class("Adder");


    // Tuning parameters: use at most 2000 
    // machines and 100 MB of memory per task 

    spec.set_machines(2000); 
    spec.set_map_megabytes(100); 
    spec.set_reduce_megabytes(100);

    // Now run it 
    MapReduceResult result; 
    if (!MapReduce(spec, &result)) abort();

    // Done: ’result’ structure contains info
    // about counters, time taken, number of 
    // machines used, etc.
    return 0;
}
```

# 5. Lab1



