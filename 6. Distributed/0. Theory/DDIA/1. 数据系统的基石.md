# 1. Basic Principle

Data-Intensive 和 Compute-Intensive

- Data-Intensive：数据是决定性因素，如数据的规模，数据的复杂度和数据产生与变化的速率
- Compute-Intensive：CPU主频是最大制约瓶颈

Data-Intensive Application的各种组件

- 数据库(database)：存储数据，以便自己或其他应用程序之后能再次找到
- 缓存(cache)：记住开销昂贵操作的结果，加快读取速度
- 搜索索引(search indexes): 允许用户按关键字搜索数据，或以各种方式对数据进行过滤
- 流处理(stream processing): 向其他进程发送消息，进行异步处理
- 批处理(batch processing): 定期处理累积的大批量数据
- 消息队列(Message Queue): 进行消息的传送和分发

设计目标

- `可靠性`（Reliability）
  - 系统在 **困境**（adversity，比如硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）
- `可伸缩性`（Scalability）
  - 有合理的办法应对系统的增长（数据量、流量、复杂性）
- `可维护性`（Maintainability）
  - 许多不同的人（工程师、运维）在不同的生命周期，都能高效地在系统上工作（使系统保持现有行为，并适应新的应用场景）

## 1.1 可靠性(Reliability)

个人对于可靠性的解释

- **故障** 通常定义为系统的一部分状态偏离其标准
- **失效** 则是系统作为一个整体停止向用户提供服务
- 故障的概率不可能降到零，因此最好设计容错机制以防因 **故障** 而导致 **失效**

常见的故障有：

- `硬件故障`：
  - 故障情景：硬盘崩溃，内存故障，电网停电等；
  - 解决方式：硬件冗余(准备备用硬件，例如备用机器、柴油发电机)、软件容错(如滚动升级)
- `软件故障`：
  - 故障情景：操作系统bug、同一个机器的其他进程占满资源
  - 解决方式：自动化、全方位测试；监控进程行为；进程隔离等等
- `人为故障`：
  - 故障情景：致软件的大多数问题都是配置问题
  - 解决方式：优秀的文档；优秀的抽象和 API；允许简单、快速的恢复(也就是回滚)

## 1.2 可扩展性(Scalability)

- 定义： 系统应对负载增长的能力。换句话说，如果负载增加，如何增加较少的计算资源来满足需求？
- 描述负载：QPS，KPS，cache 的命中率，活跃用户等。
- 描述性能：吞吐，延迟(请求花费在处理上的时间)，响应时间(处理请求时间+ 网络延迟 + 排队延迟)；除了平均值还会用百分位点(例如 p99，高百分位点叫尾部延迟)

应对负载增加的方式：扩容,垂直扩展和水平扩展

- 垂直扩展：增加机器规格
- 水平扩展：增加机器数量
- 一般的发展顺序是先垂直扩展，后来发现太贵就水平扩展，如果是有状态服务就引出了分布式

## 1.3 可维护性(Maintainability)

可维护性包含三大方面：

- 可操作性：一个团队要能监控服务运行状况、追踪问题原因并修复各种问题、及时更新软件；为此，监控工具、自动化工具、文档等极为重要
- 简单性：使用抽象，将细节隐藏于一个简单易懂的外观下。同时尽可能地解耦各个模块
- 可演化性：可以支持变化的需求

# 2. Data Models

第二章解决的核心问题：不同数据模型之间的特点

- 为什么已经有 SQL 了我们还需要其他数据模型
- 随着数据量地增大，我们需要更大地数据集或者更高地吞吐
- 渴望跳出关系数据库模式的限制，想要一个更自由的数据模型
- SQL 存在对象关系不匹配的问题。也就是存储在关系表中的数据和程序代码中的数据是需要转化的

几种模型的比较：

- 关系数据库：一个表就是元组的集合。它的数据模式在写的时候就被确定

- - 优势：更好的支持一对多和多对多关系

- 文档数据库： JSON、XML。它的数据模式在写的时候还不被确定，在读的时候才会确定。

- - 优势：由于其局部性拥有更好的性能
  - 局限性：就算只修改/查询文档的一小部分也要重写/读取整个文档，因此建议保持小文档

- 图数据库：顶点和边组成的图

- - 存储模式：就如同图一样，可以用三元组(顶点，边，顶点)存储；也可以用两个表表示，一个存储顶点(属性、入边集合、出边集合、node_id)，一个存储边(属性、起点、终点、关系类型、edge_id)。前者称之为三元组模型，后者称之为属性图模型
  - 顶点和边都有 id，可以快速索引；
  - 适用于关联度很高的数据

几种查询语言：

- 命令式查询：类似 C 代码，用循环&if 等，可以控制每一步怎么做
- 声明式查询：严格遵循关系代数，例如SQL
- MapReduce 查询：介于命令式和声明式之间，使用 map 操作和 reduce 操作
- Cypher查询：专为属性图模型设计
- SPARQL查询：转为三元组模型设计

# 3. Storage Engines

### hash索引

- key值存在hash table中(全内存)， key-value对顺序写入日志（write ahead log）， 日志分段存储（以段为单位进行压缩，剔除重复数据）
- 故障恢复: 遍历日志，将key重新取出来构成hash table。为了减少故障恢复遍历日志的时间，通常会定期将hashtable生成快照存到磁盘，重启时先读取快照中的key, 然后从快照生成的时间点开始读取日志。
- 优势: 全内存加载的hashtable查找速度快, 合并段以及追加段的操作为顺训写，对ssd友好
- 缺点: hash表不适合磁盘存储，必须放入内存中，对于value较小，且不重复key数量较多的场景需要耗费大量内存; 不支持区间查询; hash表变满时，继续增长代价昂贵。（hash算法以及扩充hash表的重hash见[hash算法](https://github.com/Little-Wallace/ddia-note/blob/master/projects/hash.md)）

### LSM-Tree

即， Log Structure Merged Tree，将随即写操作转化为顺序写操作的数据结构。 leveldb的核心数据结构包括两个部分: memtable和sstable（sorted string table）， memtable可以是skiplist或者AVL之类的数据结构，sstable则是按照key有序的key-value对数组。 当memtable的内存占用达到一定阙值时，转化为sstable，然后顺序写入磁盘。 查找某一个key时，先检查memtable中是否存在，然后从新到旧查询所有的sstable，如果查到了就提前返回结果。为了减少查询多个sstable带来的开销，后台线程会按照一定的策略对sstable进行合并。

- 故障恢复： sstable中记录了数据在日志中的位置，因此只需要恢复memtable丢失的那部分数据。
- 实现细节见[leveldb](https://github.com/Little-Wallace/ddia-note/blob/master/projects/leveldb.md)。
- 优点:由于写入操作只发生在内存中以及顺序写如日志（为了防止内存数据丢失，即WAL）, 因此写入效率高, 对ssd友好，压缩效率高。
- 缺点:读放大，每次查找需要查找多个sstable，在密集写入的情况下，大量sstable来不及被合并，会严重影响到查询速度; 写放大， 同一个key会被反复写入sstable；合并操作会影响正常读写操作的磁盘IO; 在事务型数据库中，对某个范围的key加锁不方便

### B-Tree

> B Tree 与B+ Tree算法细节见[wiki](https://zh.wikipedia.org/zh-hans/B%2B树)

将数据切割成4KB大小的页，同时B tree的每一个节点也是4KB大小的页，这样的数据结构相比于红黑树这样的AVL更适合磁盘存储，因为现代计算机磁盘的访问和存储通常都以4KB为单位, 即写入的时候即使只更改了1B的数据，也要将这4KB的页完全擦除重写。

### 二级索引

通常用在关系型数据库中，对table的某一列建立二级索引，key是该列的值，value则是主键(或者唯一标识的ID)

### 聚集索引

索引和值存储在一起。

### 多列索引

- 级联索引(concatenated index): 将几个字段的值拼接起来，然后建立索引。
- 多维索引: 如查询某个经纬度范围内的餐馆
  - 数据结构: KD-Tree, R-Tree.
  - 其他实现：利用geo hash 将范围拆分成多个不同层级小范围，然后建立索引。