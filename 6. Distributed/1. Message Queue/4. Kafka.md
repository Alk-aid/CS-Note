# 1. Main Concepts and Terminology

## 1.1 Definition

Kafka的定义：

- 传统定义：`分布式`的 基于 `发布 / 订阅` 模式 的 `消息队列`
- 最新定义：`分布式事件流平台(Event Streaming Platform)`

作为一个事件流平台，所必须具备的三个关键能力

- `消息队列`：发布和订阅消息(流)
- `存储系统`：持久化 和 可靠的存储事件流
- `流处理平台`：Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了完整的流式处理类库

## 1.2 Terminology

Message

- 组成：key，vaule，timestamp，optional metadata headers
- 在被消费后，Message并不会被删除，而是保存直到他们过期
- 具有相同key的Message会被写入到相同的分区中去

Partition

- 为方便拓展，以及提高并发度，一个topic可以分为多个partition

- 每个 partition 是一个有序的队列，给定分区的任意consumer都会按照写入顺序读取对应的Message
- 一个消费者组里面不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息
- Partition在存储层面可以看作是一个可追加的日志文件

offset：

- offset 是消息在分区中的唯一标识，
- Kafka 通过它来保证消息在分区内的顺序性
- Kafka 保证的是分区有序而不是主题有序

Leader and Follower

- 为了提高fault-tolerant 和 highly-available，为每个partition增加若干副本，从而保证数据不丢失
- 常见的生产环境设置的replication factor 是 3

- leader ：生产者发送数据的对象，以及消费者消费数据的对象都是 leader
- follower ：只负责与leader 副本的消息同步。leader 发生故障时，某个 follower 会成为新的 leader
- 分区中的所有副本统称为AR(Assigned Replicas), 与leader保持一定同步的称之为ISR(In-Sync Replicas，包括leader)。与leader同步滞后过多的副本(不包括leader)组成OSR。AR = ISR + OSR

HW 和 LEO:

- HW: High Watermark，用来标识某一特定的offset，消费者只可以拉取到这个offset之前的消息
- LEO: Log End Offset，标识当前日志文件中下一条待写入消息的offset
- 分区ISR 集合中的每个副本都会维护自身的LEO ，而ISR 集合中最小的LEO即为分区的HW
- 比同步复制性能好，同时避免了异步复制存在的数据丢失问题

Kafka四大核心API:

- Producer API: 发布消息到1个或多个topic中
- Consumer API: 订阅一个或多个topic，并处理产生的消息
- Streams API: 处理器，将输入流转化为输出流
- Connector API: 构建和运行可重用的数据导入/导出连接器, 也就是连接器produce和consume的Message来自外部系统

消费模型

- 消费者组：组内每个消费者并行消费，也就是一个partition只能由一个 组内 消费者消费，并按顺序消费数据

- 队列：消费者组允许同名的消费者组成员瓜分处理
- 发布-订阅：消息被广播给多个消费者组
- kafka的每个topic都具有这两种模式

# 2. Producer

## 2.1 客户端开发

```java
public class TestProducer {
    public static final String BROKERLIST = "49.235.253.211:9092";
    public static final String TOPIC = "my-topic";
    public static Properties initConfig() {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKERLIST);
        props.put(ProducerConfig.ACKS_CONFIG, "all");
        props.put(ProducerConfig.RETRIES_CONFIG , 0);
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
        props.put(ProducerConfig.LINGER_MS_CONFIG, 1);
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        return props;
    }
    public static void main(String[] args) {
        Properties props = initConfig();
        Producer<String, String> producer = new KafkaProducer<>(props);
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, Integer.toString(1), Integer.toString(1));
        // 同步发送
        producer.send(record);
        // 异步发送
        producer.send(record,(metadata, exception) -> {
            if (exception != null)
                exception.printStackTrace();
            else {
                System.out.println(metadata.topic() + "-" + metadata.partition() + ":" + metadata.offset());
            }
        });
        producer.close();
    }
}
```

## 2.2 ProducerRecord

```java
public class ProducerRecord<K, V> {
    private final String topic;
    private final Integer partition;
    private final Headers headers;
    // 是消息的附加信息，用来指定消息的键
    // 还可以用来计算分区号进而可以让消息发往特定的分区，同一个key的消息会被划分到同一个分区中(相当于二次分类)
    private final K key;
    private final V value;
    private final Long timestamp;
}
```



# 3. Consumer





# 2. Persistence

> - 因为kafka的持久化队列建立在O(1)的读和apeend上面，就像日志系统一样
> - 从而使得kafka无需任何性能损失就可以访问几乎无限制的磁盘空间
> - 因此在kafka中消息被消费后不是立马被删除，而是可以保存较长的一段时间



## 1.3 文件存储机制

存储结构

- 一个topic分为多个partition
- 一个partition分为多个segment
- 一个segment对应.log文件 和 .index文件
- 其中消息会不断被追加到log文件末尾
- 同时为了加快访问速度，使用.index文件保存大量的索引信息，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址

.index 和 .log文件所在的文件夹

- 该文件夹的命名规则为：topic 名称+分区序号
- index 和 log 文件以当前 segment 的第一条消息的 offset 命名

---

对于每个topic，Kafka集群会维护一个分区Log

- 每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加
- 分区中的消息都被分了一个序列号，称之为偏移量(offset)
- Kafka集群保持所有的消息，直到它们过期（无论消息是否被消费），消费者所持有的仅有的元数据就是offset
- 每个partition仅由同一个消费者组中的一个消费者消费到。并确保消费者是该partition的唯一消费者，并按顺序消费数据

# 2. API

