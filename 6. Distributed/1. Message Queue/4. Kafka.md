# 1. Main Concepts and Terminology

## 1.1 Definition

Kafka的定义：

- 传统定义：`分布式`的 基于 `发布 / 订阅` 模式 的 `消息队列`
- 最新定义：`分布式事件流平台(Event Streaming Platform)`

作为一个事件流平台，所必须具备的三个关键能力

- `消息队列`：发布和订阅消息(流)
- `存储系统`：持久化 和 可靠的存储事件流
- `流处理平台`：Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了完整的流式处理类库

## 1.2 Terminology

1. Message

- 组成：key，vaule，timestamp，optional metadata headers
- 在被消费后，Message并不会被删除，而是保存直到他们过期
- 具有相同key的Message会被写入到相同的Partition中去

2. Partition

- 为方便拓展，以及提高`并发度`，一个topic可以分为多个partition

- 每个 partition 是一个有序的队列，给定分区的任意consumer都会按照写入顺序读取对应的Message
- 一个消费者组里面不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息
- Partition在存储层面可以看作是一个可追加的日志文件

3. offset：

- `Broker中的offset`: 每条消息都有一个offset值来表示它在分区中的位置
- `消费者中的offset`: 消费者在消费时，也维护一个offset，表示消费到分区中的某个消息所在的位置

- Kafka 通过offset来保证消息在分区有序性；Kafka 保证的是分区有序而不是主题有序

4. Leader and Follower：多副本机制

- 为了提高fault-tolerant，为每个partition增加若干副本，从而保证数据不丢失
- 常见的生产环境设置的replication factor 是 3
- leader ：生产者发送数据的对象，以及消费者消费数据的对象都是 leader
- follower ：只负责与leader 副本的消息同步。leader 发生故障时，某个 follower 会成为新的 leader
- 分区中的所有副本统称为AR(Assigned Replicas), 与leader保持一定同步的称之为ISR(In-Sync Replicas，包括leader)。与leader同步滞后过多的副本(不包括leader)组成OSR。AR = ISR + OSR 

5. HW 和 LEO:

- HW: High Watermark，用来标识某一特定的offset，消费者只可以拉取到这个offset之前的消息
- LEO: Log End Offset，标识当前日志文件中下一条待写入消息的offset
- 分区ISR 集合中的每个副本都会维护自身的LEO ，而ISR 集合中最小的LEO即为分区的HW
- 比同步复制性能好，同时避免了异步复制存在的数据丢失问题

6. Kafka四大核心API:

- Producer API: 发布消息到1个或多个topic中
- Consumer API: 订阅一个或多个topic，并处理产生的消息
- Streams API: 处理器，将输入流转化为输出流
- Connector API: 构建和运行可重用的数据导入/导出连接器, 也就是连接器produce和consume的Message来自外部系统

7. 消费模型

- 消费者组：组内每个消费者并行消费，也就是一个partition只能由一个 组内 消费者消费，并按顺序消费数据

- 队列：消费者组允许同名的消费者组成员瓜分处理
- 发布-订阅：消息被广播给多个消费者组
- kafka的每个topic都具有这两种模式

## 1.3 消息不重复消费

出现重复消费的原因：

- 服务端侧已经消费的数据没有成功提交 offset（根本原因）
- Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance

解决方案：

- 消费消息服务做幂等校验，比如 Redis 的set、MySQL 的主键等天然的幂等功能。这种方法最有效
- 将 **`enable.auto.commit`** 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset

## 1.4 消息丢失问题

1. 生产者丢失数据：

- 原因：send是异步发送的，调用send以后，生产者就判断消息发送成功；但是因为网络原因，导致消息并没有成功到达Broker中
- 解决：使用get()将异步发送转化为同步发送 |  添加回调函数，当消息发送失败以后可以检查失败原因 ｜ 设置重试次数(一般为3)

```java
ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
future.addCallback(
  	result -> logger.info("生产者成功发送消息到topic:{} partition:{}的消息", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
  	ex -> logger.error("生产者发送消失败，原因：{}", ex.getMessage()));
```

2. 消费者丢失数据

- 原因：消费者拉取消息，在消费之前就自动提交offset，但是还没消费 消费者就宕机了，会导致数据丢失
- 解决方案：关闭自动提交offset，**每次在真正消费完消息之后再自己手动提交 offset**。但是这个会导致消息重复被消费问题

3. Kafka丢失数据

- 原因：kafka有多副本机制，一般不会出现数据丢失问题；但是如果leader挂了，leader中的数据还未同步到follower中，就会导致数据丢失问题
- 解决方案：
  - 当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader 
  - 一般情况下我们还需要设置 **min.insync.replicas> 1** ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。一般推荐设置成 **replication.factor = min.insync.replicas + 1**
  - 一般会为 topic 设置 **replication.factor >= 3**。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性
  - acks 的默认值即为1，代表我们的消息被leader副本接收之后就算被成功发送。当我们配置 **acks = all** 代表则所有副本都要接收到该消息之后该消息才算真正成功被发送

## 1.5 Rebalance

1. `机制`：将⼀个Topic下的多个Queue在同⼀个Consumer Group中的多个Consumer间进行重新分配的过程

2. `产生原因`: 消费者所`订阅Topic的Partition数量发生变化`，或消费者组中`消费者的数量发生变化`

3. `过程`: 

- 所有消费成员都向Coordinator发送请求，请求入Consumer Group。一旦所有成员都发送了请求，Coordinator会从中选择一个Consumer担任Leader的角色，并把组成员信息以及订阅信息发给Leader
- Leader开始分配消费方案，指明具体哪个Consumer负责消费哪些Topic的哪些Partition。一旦完成分配，leader会将这个方案发给Coordinator。Coordinator接收到分配方案之后会把方案发给各个Consumer，这样组内的所有成员就都知道自己应该消费哪些分区了

4. `优点`：提升消息的并行消费能力

5. `缺点`：

- `重复消费`: 因为默认情况下采用的是异步提交, 导致Broker的offset与Consumer实际消费的消息并不一致，这个不一致的差值就是可能会重复消费的消息

- `消费暂停`:在rebalance分配完前，需要暂停部分队列的消费

  

## 1.6 Zk的作用

1. **Broker 注册** ：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 `/brokers/ids` 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
2. **Topic 注册** ： 在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
3. **负载均衡** ：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

# 2. Persistence

> - 因为kafka的持久化队列建立在O(1)的读和apeend上面，就像日志系统一样
> - 从而使得kafka无需任何性能损失就可以访问几乎无限制的磁盘空间
> - 因此在kafka中消息被消费后不是立马被删除，而是可以保存较长的一段时间



## 1.3 文件存储机制

存储结构

- 一个topic分为多个partition
- 一个partition分为多个segment
- 一个segment对应.log文件 和 .index文件
- 其中消息会不断被追加到log文件末尾
- 同时为了加快访问速度，使用.index文件保存大量的索引信息，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址

.index 和 .log文件所在的文件夹

- 该文件夹的命名规则为：topic 名称+分区序号
- index 和 log 文件以当前 segment 的第一条消息的 offset 命名

---

对于每个topic，Kafka集群会维护一个分区Log

- 每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加
- 分区中的消息都被分了一个序列号，称之为偏移量(offset)
- Kafka集群保持所有的消息，直到它们过期（无论消息是否被消费），消费者所持有的仅有的元数据就是offset
- 每个partition仅由同一个消费者组中的一个消费者消费到。并确保消费者是该partition的唯一消费者，并按顺序消费数据
