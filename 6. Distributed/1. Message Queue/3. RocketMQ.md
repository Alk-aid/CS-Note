# 1. Quick Start

![](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/09a78b0075d7472eb6e1b18631499c48.png)

## 1.1 名词解释

1. `消息(message)`：数据的载体，每条消息必须属于一个topic

2. `主题(topic)`： 

- 一类消息的集合，是RocketMQ进行消息订阅的基本单位
- 生产者可以发送多种Topic信息，消费者只能订阅和消费一种Topic的消息

3. `标签(Tag)`: 用于同一topic下区分不同类型的消息, Topic是消息的一级分类，Tag是消息的二级分类

4. `队列(Queue)`: 存储消息的物理实体，一个Topic中可以包含多个Queue

5. `Broker`: 每个Broker中会创建出相应数量的分区（Queue），每个Queue大小相同

6. `消息标识(MessageId/Key)`: msgId、offsetMsgId与key都称为消息标识

- **msgId**：由producer端生成，其`生成规则`为：`producerIp + 进程pid + MessageClientIDSetter类的ClassLoader的hashCode +当前时间 + AutomicInteger自增计数器`
- **offsetMsgId**：由broker端生成，其生成规则为：`brokerIp + 物理分区的offset（Queue中的偏移量）`
- **key**：由用户指定的业务相关的唯一标识

## 1.2 工作流程

1. 启动Name Server，Name Server启动后开始监听端口，等待Broker、Producer、Consumer连接

```shell
> nohup sh bin/mqnamesrv &
> tail -f ~/logs/rocketmqlogs/namesrv.log
The Name Server boot success...
```

2. 启动Broker时，Broker会与所有的Name Server建立并保持长连接，然后每30秒向Name Server定时发送心跳包。(注册)

```shell
> nohup sh bin/mqbroker -n localhost:9876 &
> tail -f ~/logs/rocketmqlogs/broker.log 
The broker[%s, 172.30.30.233:10911] boot success...
```

3. 创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，当然，在创建Topic时也会将Topic与Broker的关系写入到Name Server中。不过，这步是可选的，也可以在发送消息时自动创建Topic

4. Producer发送消息

- 启动时先跟Name Server集群中的其中一台建立长连接，并从Name Server中获取路由信息，即当前发送的Topic消息的Queue与Broker的地址（IP+Port）的映射关系
- 然后根据算法策略从队选择一个Queue，与队列所在的Broker建立长连接从而向Broker发消息
- 当然，在获取到路由信息后，Producer会首先将路由信息缓存到本地，再每30秒从NameServer更新一次路由信息

5. Consumer跟Producer类似，

- 跟其中一台Name Server建立长连接，获取其所订阅Topic的路由信息
- 然后根据算法策略从路由信息中获取到其所要消费的Queue
- 然后直接跟Broker建立长连接，开始消费其中的消息
- Consumer在获取到路由信息后，同样也会每30秒从Name Server更新一次路由信息。不同于Producer的是，Consumer还会向Broker发送心跳，以确保Broker的存活状态

## 1.3 配置文件

192.168.100.131 机器上Master Broker 的配置文件：

```shell
namesrvAddr=192.168.100.131:9876; 192.168.100.132:9876
brokerClusterName=DefaultCluster
# Master 和Slave 使用相同的BrokerName
brokerName=broker-a
# 0 表示Master, 大于0表示Slave
brokerid=0
# 与fileReservedTim巳参数呼应，表明在几点做消息删除动作，默认值04 表示凌晨4 点。
deleteWhen=04
# 在磁盘上保存消息的时长，单位是小时，自动删除超时的消息
fileReservedTime=48

# 表示复制R,ASYNC_MASTER,SLAVE; 
# SYNC: 消息写入master后，master会等待slave同步数据成功后才向producer返回成功ACK
# ASYNC: 消息写入master后，master立即向producer返回成功ACK，无需等待slave同步数据成功
brokerRole=SYNC_MASTER

# 表示刷盘策略，有SYNC_FLUSH ASYNC_FLUSH；SYNC表示消息持久化到磁盘算成功，ASYNC表示持久化到PageCahce算成功
flushDiskType=ASYNC FLUSH
# 服务器IP
brokerIP1=49.235.253.211
# Broker监听的端口
listenPort=10911
# 存储消息以及一些配置信息的根目录
storePathRootDir=/home/rocketmq/store-a
```

192.168.100.132 机器上Slave Broker 的配置文件

```shell
namesrvAddr=192.168.100.131:9876; 192.168.100.132:9876
brokerClusterName=DefaultCluster
brokerName=broker-a
brokerid=1
deleteWhen=04
f 工leReservedTime=48
brokerRole=SLAVE
flushDiskType=ASYNC_FLUSH
# 服务器IP
brokerIP1=49.235.253.211
listenPort=11011
storePathRootDir=/home/rocketmq/store-a
```

## 1.4 代码演示

https://rocketmq.apache.org/docs/simple-example/

## 1.5 管理命令

- 执行命令方法：`sh bin/mqadmin {command} {args}`
- 几乎所有命令都需要配置-n表示NameServer地址，格式为ip:port

https://www.cnblogs.com/williamjie/p/9377208.html

## 1.6 读/写队列

`从物理上来讲，读/写队列是同一个队列`。所以，不存在读/写队列数据同步问题。读/写队列是逻辑上进行区分的概念。`一般情况下，读/写队列数量是相同的`。

那么，为什么要这样设计呢？其这样设计的目的是为了，`方便Topic的Queue的缩容`。

- 例如，原来创建的Topic中包含16个Queue，如何能够使其Queue缩容为8个，还不会丢失消息？
- 可以动态修改写队列数量为8，读队列数量不变。此时新的消息只能写入到前8个队列，而消费都消费的却是16个队列中的数据。
- 当发现后8个Queue中的消息消费完毕后，就可以再将读队列数量动态设置为8。整个缩容过程，没有丢失任何消息。

> perm用于设置对当前创建Topic的操作权限：2表示只写，4表示只读，6表示读写

## 1.7 Topic的创建模式

手动创建Topic时，有两种模式：

- `集群模式`：该模式下创建的Topic在该集群中，所有Broker中的Queue数量是相同的。`(全局定义)`
- `Broker模式`：该模式下创建的Topic在该集群中，每个Broker中的Queue数量可以不同。

自动创建Topic

- `默认采用的是Broker模式`，会为每个Broker默认创建4个Queue。

## 1.8 集群分类

**多Master**

- broker集群仅由多个master构成，不存在Slave。同一Topic的各个Queue会平均分布在各个master节点上。
- 在磁盘配置了RAID10有以下优缺点

- `优点`：*配置简单，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），所以单个Master宕机或重启维护对应用无影响，性能最高；*
- `缺点`：*单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅（不可消费），消息实时性会受到影响*

**多Master多Slave模式-异步复制**

- broker集群由多个master构成，每个master又配置了多个slave（RAID10一般只配置一个slave）。master与slave的关系是主备关系，即master负责处理消息的读写请求，而slave仅负责消息的备份与master宕机后的角色切换
- 该模式的最大特点之一是，当master宕机后slave能够`自动切换`为master。不过由于slave从master的同步具有短暂的延迟（毫秒级），所以当master宕机后，这种异步复制方式可能会存在少量消息的丢失问题。

**多Master多Slave模式-同步双写**

- 该模式与异步复制模式相比，优点是消息的`安全性更高`，不存在消息丢失的情况。但单个消息的RT(响应时间)略高，从而导致性能要略低（大约低10%）
- 该模式存在一个大的问题：对于目前的版本，Master宕机后，Slave不会自动切换到Master（致命问题）

**最佳实践**

- 一般会为Master配置RAID10磁盘阵列，然后再为其配置一个Slave。即利用了RAID10磁盘阵列的高效、安全性，又解决了可能会影响订阅的问题。-------多M多S+RAID10阵列

# 2. Producer

消息生产者：Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递

- 生产者都是`以生产者组（Producer Group）的形式`出现的
- 一个生产者组发送相同Topic(可以同时发送多个topic)类型的消息

---

- RocketMQ支持三种消息：普通消息，顺序消息，事务消息
- RocketMQ支持三种发送方式：同步发送，异步发送，单向发送

## 2.1 Message

```java
public class Message implements Serializable {
   	// topic
    private String topic;
    // 消息扩展信息，包括tag，keys，延迟级别
    private Map<String, String> properties;
    // 消息体
    private byte[] body;
    private String transactionId;
    
    public void setKeys(String keys);
    public void setKeys(Collection<String> keys);
    
    public void setTags(String tags);
    public void setDelayTimeLevel(int level);
    public void setTopic(String topic);
    public void putUserProperties(final String name, final String value);
}
```

消息的种类:

- 普通消息(并发消息)：无顺序，生产消费都是并行进行的
- 分区有序消息：把一个Topic消息分为多个分区保存 和 消费，一个分区内的消息遵循FIFO原则
- 全局有序消息：把Topic的分区设置为1，所有的消息都遵循FIFO原则
- 延迟消息：消息发送后，消费者在一定时间后 或者 指定时间点才能进行消费
- 事务消息：保证多个操作同时成功或失败时才能消费数据

## 2.2 生产者高可用

高可用：不管Broker，Name Server出现什么情况，发送消息都不要出现未知状态或者消息丢失

客户端保证HA

- 第一种保证机制：重试机制

- 第二种保证机制：客户端容错，RocketMQ可以选择发送延迟级别较低的Broker来发送消息

Broker保证HA

- Broker可以配置主从同步复制来保证消息不会被丢失
- 当然绝大部分常见都是配置主从异步复制来提高效率

## 2.3 生产消息

Producer将消息写入到某Broker中的某Queue中，其经历了如下过程：

- Producer发送消息之前，会先向`NameServer`发出请求来`获取消息Topic的路由信息`
- NameServer返回该`Topic的路由表及Broker列表`
- Producer根据代码中指定的Queue选择策略，从Queue列表中选出一个队列，用于后续存储消息
- Produer对消息做一些特殊处理，例如，消息本身超过4M，则会对其进行压缩
- Producer向选择出的Queue所在的Broker发出RPC请求，将消息发送到选择出的Queue

---

Queue选择算法：对于无序消息，其Queue选择算法，也称为消息投递算法

- **轮询算法**:
  - *保证了每个Queue中可以均匀的获取到消息*
  - 可能因为某些Queue投递延迟较严重，从而`导致Producer的缓存队列中出现较大的消息积压，影响消息的投递性能`。
- **最小投递延迟算法**
  - 统计每次消息投递的时间延迟，然后根据统计将消息投递到时间延迟最小的Queue。如果延迟相同，则采用轮询算法投递
  - 存在问题：消息在Queue上的`分配不均匀`。投递延迟小的Queue其可能会存在大量的消息。



# 3. Consumer

消息消费者： 一个消息消费者会从Broker服务器中获取到消息，并对消息进行相关业务处理

- 消息消费者都是以消费者组的形式出现的，这类`Consumer消费的是同一个Topic类型的消息`
- 一个消费者组只能消费一个Topic的消息，不能同时消费多个Topic消息
- 一个Topic类型的消息可以被多个消费者组同时消费

## 3.1 获取消息

常规获取消息的方式

- `pull拉取`：客户端不断轮询请求服务端，来获取新的消息
- `push推送`(发布-订阅)：当服务器有消息时，服务器将消息推送到客户端

RocketMQ的push 和 pull模式本质上都是采用pull的方式来获得消息的

- PUSH: consumer把轮询过程封装了，并注册监听器，获得消息以后就调用监听器的consumerMessage()来进行消费
- PULL(已经过时了) : 需要用户自己去获取MessageQueue的集合，然后遍历MessageQueue集合，针对每一个MessageQueue批量取消息，每取完一次，记录该队列下一次要取的开始offset

push模式的优缺点：

- 优点：实时性高
- 缺点：consumer处理消息慢，而MQ不断地向消费者Push消息，可能会导致消费者端的缓冲区溢出
- 缺点：如果consumer过于多，服务器需要主动给大量consumer推送消息的话，服务器端的压力会无限制的增大

Pull的优缺点：

- 优点：主动权在consumer端
- 缺点：pull间隔不好把控，太短容易处于忙等状态，浪费资源；太长会导致消息处理不及时

> RocketMQ通过长轮询的方式来兼顾PULL的优点 和 Push的实时性

- **消费者如果第一次尝试Pull消息失败**， 并不立即给消费者客户端返回Response的响应
- 而是先hold住并且挂起请求（将请求保存至pullRequestTable本地缓存变量中）
- 然后Broker端的后台线程会从pullRequestTable本地缓存变量中不断地去取，比较待拉取消息的偏移量是否小于消费队列最大偏移量
- 如果条件成立，则返回消息给服务器

```java
// push模式代码
public class SyncConsumer {
    public static void main(String[] args) throws MQClientException {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("Alk-aid_MQ_Consumer_Group");
        consumer.setNamesrvAddr("49.235.253.211:9876");
        consumer.setConsumeFromWhere(ConsumeFromWhere. CONSUME_FROM_FIRST_OFFSET);
        consumer.setMessageModel(MessageModel.BROADCASTING);
        consumer.subscribe("TopicTest", "*");

        consumer.registerMessageListener((MessageListenerConcurrently) (list, consumeConcurrentlyContext) -> {
            System.out.printf(Thread.currentThread().getName () + "Receive New Messages: " + list  + "%n" );
            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS ;
        });
        //Launch the consumer instance.
        consumer.start();
        System.out.printf("Consumer Started.%n");
    }
}
```

## 3.2 消费消息

消费者组对于`消息消费`的模式又分为两种：集群消费Clustering和广播消费Broadcasting

- `广播消费`：每条消息都会被发送到Consumer Group中的每个Consumer
- `集群消费`：每条消息只会被发送到Consumer Group中的某个Consumer

---

消息进度保存：

- `广播消费`：消费进度保存在consumer端, 因为每个consumer的消费进度是不同
- `集群消费`：消费进度保存在broker中，消费进度是需要共享

---

Queue分配算法：一个Consumer可以同时消费多个Queue中的消息, 

- **平均分配策略**： 根据`avg = QueueCount / ConsumerCount`的计算结果进行分配的
- **环形平均策略**：根据`消费者的顺序，依次在由queue队列组成的环形图中逐个分配`
- **一致性hash策略**：将consumer的hash值作为Node节点存放到hash环上，然后将queue的hash值也放到hash环上，通过`顺时针方向`，距离queue最近的那个consumer就是该queue要分配的consumer。但是存在分配不均的问题。
  - 可以`有效减少由于消费者组扩容或缩容所带来的大量的Rebalance`。避免减少Rebalance
- **同机房策略**：`根据queue的部署机房位置和consumer的位置`，过滤出当前consumer相同机房的queue。然后`按照平均分配策略或环形平均策略对同机房queue进行分配`。如果没有同机房queue，则按照平均分配策略或环形平均策略对所有queue进行分配。

## 3.3 提交方式

提交方式：

- `同步提交`：*consumer提交了其消费完毕的一批消息的offset给broker后，`需要等待broker的成功ACK`*，才能消费下一组。*在等待ACK期间，consumer是阻塞的*
- `异步提交`：*consumer提交了其消费完毕的一批消息的offset给broker后，`不需要等待broker的成功ACK`*，就可以消费下一批消息

## 3.4 Rebalance

- `前提`是`集群消费`

- `机制`：将⼀个Topic下的多个Queue在同⼀个Consumer Group中的多个Consumer间进行重新分配的过程
- `产生原因`: 消费者所`订阅Topic的Queue数量发生变化`，或消费者组中`消费者的数量发生变化`
- `优点`：提升消息的并行消费能力
- `缺点`：
  - 消费暂停：在rebalance分配完前，需要暂停部分队列的消费
  - 消费重复：因为默认情况下采用的是异步提交, 导致Broker的offset与Consumer实际消费的消息并不一致，个不一致的差值就是可能会重复消费的消息

## 3.5 消费幂等

> **幂等**：`若某操作执行多次与执行一次对系统产生的影响是相同的，则称该操作是幂等的`。

- `概念`：当出现消费者对某条消息重复消费的情况时，重复消费的结果与消费一次的结果是相同的，并且多次消费并未对业务系统产生任何负面影响，那么这个消费过程就是消费幂等的

- `产生`：消息被重复消费的三种情况
  - **发送时消息重复**：一条消息发送成功并持久化，但因为Broker对Producer的应答失败，导致重复发送
  - **消费时消息重复: ** 一条消息被消费成功，但是因为Consumer对Broker的应答失败，导致重复发送
  - **Rebalance时消息重复**
- `解决方案`: 主要解决`幂等令牌`，`唯一性处理`
  - `幂等令牌`: 通常指具备`唯⼀业务标识的字符串`, 如字符串，流水号，一般由Producer随着消息一同发送来的
  - `唯一性处理`：服务端通过采用⼀定的算法策略，保证同⼀个业务逻辑不会被重复执行成功多次
  - 方案：

> 1. 首先通过缓存去重。在缓存中如果已经存在了某幂等令牌，则说明本次操作是重复性操作；若缓存没有命中，则进入下一步。
> 2. 在唯一性处理之前，先在数据库中查询幂等令牌作为索引的数据是否存在。若存在，则说明本次操作为重复性操作；若不存在，则进入下一步。（之所以第二步要判断是因为一般缓存中的数据是具有有效期的）
> 3. 在同一事务中完成三项操作：唯一性处理后，将幂等令牌写入到缓存，并将幂等令牌作为唯一索引的数据写入到DB中。

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/image-20220410203710343.png" alt="image-20220410203710343" style="zoom:50%;" />

## 3.6 消息堆积与消费延迟

- `概念`：消息处理流程中，如果Consumer的消费速度跟不上Producer的发送速度，MQ中未处理的消息会越来越多（`进的多出的少`），这部分消息就被称为`堆积消息`。消息出现堆积进而会造成消息的`消费延迟`。

- `瓶颈`：消息堆积的主要瓶颈在于`客户端的消费能力`，而消费能力由`消费耗时和消费并发度`决定。
- `消费耗时`: 主要由CPU内部计算时间 和 外部IO操作时间决定。

> **外部IO操作型代码举例**：
>
> - 读写外部数据库，例如对远程MySQL的访问
> - 读写外部缓存系统，例如对远程Redis的访问
> - 下游系统调用，例如Dubbo的RPC远程调用，Spring Cloud的对下游系统的Http接口调用

- `消费并发度`： 由单节点线程数和节点数量共同决定
  - 通常优先调整单节点的线程数，若单机硬件资源达到了上限，则需要通过横向扩展增加节点数量（consumer数量）来提高消费并发度。



> 注意，消费耗时的优先级要高于消费并发度。即在保证了消费耗时的合理性前提下，再考虑消费并发度问题。

# 4. Name server

## 4.1 集群状态的存储结构

```java
// 路由表
private final HashMap<String/*topic*/, List<QueueData>> topicQueueTable
```

- Key是Topic的名称
- Value是一个QueueData队列，队列的长度等于 这个Topic对应的Master Broker的个数
- QueueData礼貌存储着Broker的名称，读写queue的数量等

```java
// Broker列表
private final HashMap<String, BrokerData> Broker-AddrTable
```

- 以 BrokerName 为key, 相同名称的Broker对应一个Master和多个Slave
- 以BrokerData为value，包括所属的Cluster，Master 和 Slave的地址信息

## 4.2 Name Server的功能

Name Server是一个Broker与Topic路由的注册中心，支持Broker的动态注册与发现

- **Broker管理**：接受Broker集群的注册信息并且保存下来， 提供心跳检测机制，检查Broker是否还存活。
- **路由信息管理**：
  - 每个NameServer中都保存着Broker集群的整个路由信息和用于客户端查询的队列信息
  - Producer和Conumser通过NameServer可以获取整个Broker集群的路由信息，从而进行消息的投递和消费

---

 **路由注册**：

- *在Broker节点启动时，轮询NameServer列表，与每个NameServer节点建立长连接，发起注册请求*
- *在NameServer内部维护着⼀个Broker列表，用来动态存储Broker的信息。*`NameServer集群之间没有数据通讯`
- 优点：NameServer集群`搭建简单`，`扩容简单`
- 缺点：对于Broker，`必须明确指出所有NameServer地址`。否则未指出的将不会去注册

**路由剔除**

- Broker节点为了证明自己是活着的,为了维护与NameServer间的`长连接`,会每30s最新的信息以心跳包的方式上报给NameServer
- 心跳包中包含 *BrokerId、Broker地址(IP+Port)、Broker名称、Broker所属集群名称等等*,NameServer在接收到心跳包后，会更新心跳时间戳，记录这个Broker的最新存活时间。
- NameServer每隔10秒就会扫描⼀次Broker表， 看每一个Broker的最新心跳时间戳距离当前时间是否超过120秒，如果超过，则会判定Broker失效，然后将其从Broker列表中剔除。

**路由发现**：

- `RocketMQ的路由发现采用的是Pull模型`, 客户端每30s拉取一次最新的路由

**选择策略**：*这里的客户端指的是Producer与Consumer*

- 客户端首先会生产一个随机数，然后再与NameServer节点数量取模，此时得到的就是所要连接的节点索引，然后就会进行连接。（随机获取，建立连接）
- 如果连接失败，则会采用round-robin(轮询)策略，逐个尝试着去连接其它节点

# 5. Broker

- `Remoting Module`：整个Broker的实体，负责处理来自clients端的请求。而这个Broker实体则由以下模块构成。
- `Client Manager`：客户端管理器。负责接收、解析客户端(Producer/Consumer)请求，管理客户端。例如，维护Consumer的Topic订阅信息
- `Store Service`：存储服务。提供方便简单的API接口，处理消息存储到物理硬盘和消息查询功能。
- `HA Service`：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。
  - `Master负责处理读写操作请求，Slave负责对Master中的数据进行备份`(*平常操作都是操作Master*)
  - 当Master挂掉了，Slave则会自动切换为Master去工作。所以这个Broker集群是`主备集群`
  - Master与Slave 的对应关系是通过指定相同的BrokerName、不同的BrokerId 来确定的。BrokerId为0表示Master，非0表示Slave。
- `Index Service`：索引服务。根据特定的Message key，对投递到Broker的消息进行索引服务，同时也提供根据Message Key对消息进行快速查询的功能

## 5.1 消息的存储

RocketMQ中的消息存储在本地文件系统中，默认在/root/store下面，store目录包含以下目录

- **abort**：该文件在Broker启动后会自动创建，正常关闭Broker，该文件会自动消失。若在没有启动Broker的情况下，发现这个文件是`存在`的，则说明之前Broker的关闭是`非正常关闭`。
- **checkpoint**：其中存储着commitlog、consumequeue、index文件的最后刷盘时间戳
- **commitlog**：其中存放着commitlog文件，而消息是写在commitlog文件中的
- **config**：存放着Broker运行期间的一些配置数据
- **consumequeue**：其中存放着consumequeue文件，队列就存放在这个目录中
- **index**：其中存放着消息索引文件indexFile
- **lock**：运行期间使用到的全局资源锁

### 5.1.1 commitlog文件

> commitlog文件 在源码中 称之为 mappedFile

commitlog文件

- commitlog目录中存放着很多的mappedFile文件，当前Broker中的所有消息都是落盘到这些mappedFile文件中的。
- `mappedFile文件大小为1G（小于等于1G）`，文件名由20位十进制数构成，表示当前文件的第一条消息的起始位移偏移
- 当前Broker中的消息都是被`顺序写入`到了mappedFile文件中的，并没有`被按照Topic进行分类存放`

消息单元

- mappedFile文件内容由一个个的`消息单元`构成(每一行)。
- 每个消息单元中包含 消息总长度MsgLen、消息的物理位置physicalOffset、消息体内容Body、消息体长度BodyLength、消息主题Topic、Topic长度TopicLength、消息生产者BornHost、消息发送时间戳BornTimestamp、消息所在的队列QueueId、消息在Queue中存储的偏移量QueueOffset等近20余项消息相关属性。

### 5.1.2 consumequeue

目录与文件

- 为了提高效率，会为每个Topic在`~/store/consumequeue`中创建一个目录，目录名为`该Topic名称`。
- 在该Topic目录下，会再为每个该Topic的Queue建立一个目录，目录名为`queueId`。
- 每个目录中存放着若干`consumequeue文件`，consumequeue文件是commitlog的索引文件，可以根据consumequeue定位到具体的消息。

- consumequeue文件名也由20位数字构成，表示当前文件的第一个索引条目的起始位移偏移量。`与mappedFile文件名不同的是，其后续文件名是固定的。因为consumequeue文件大小是固定不变的`。

索引条目

- `每个consumequeue文件可以包含30w个索引条目`，每个索引条目包含了三个消息重要属性

- 消息在mappedFile文件中的偏移量CommitLog Offset、 消息长度、  消息Tag的hashcode值。
- 这三个属性占20个字节，所以`每个文件的大小是固定的30w * 20字节`。

### 5.1.3 消息写入 & 拉取

**消息写入**： 先将消息写入commitLog，然后再写入consumeQueue

- Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset
- 将queueId、queueOffset等数据，与消息一起封装为消息单元, 将消息单元写入到commitlog
- 同时，形成消息索引条目, 将消息索引条目分发到相应的consumequeue

**消息拉取**

- Consumer获取到 消息所在Queue 的`消费偏移量offset`，计算出 其要消费消息 的 消息offset
- Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。
- Broker计算在该consumequeue中的queueOffset。
- 从该queueOffset处开始向后查找第一个指定Tag的索引条目。
- 解析该索引条目的前8个字节，即可定位到该消息在commitlog中的commitlog offset
- 从对应commitlog offset中读取消息单元，并发送给Consumer

> 1. 消费offset即消费进度，consumer对某个Queue的消费offset，即消费到了该Queue的第几条消息
> 2. 消息offset = 消费offset + 1

### 5.1.4 性能提升

1. RocketMQ对文件的读写操作是通过`mmap零拷贝`进行的，将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率。
2. 其次，consumequeue中的数据是顺序存放的，还引入了`PageCache的预读取机制`，使得对consumequeue文件的读取几乎接近于内存读取，即使在有消息堆积情况下也不会影响性能。

## 5.2 indexFile

`RocketMQ还提供了根据key进行消息查询的功能`

- 该查询是通过store目录中的index子目录中的indexFile进行索引实现的快速查询
- 这个indexFile中的索引数据是在`包含了key的消息`被发送到Broker时写入的。如果消息中没有包含key，则不会写入

---

indexFile的组成

- 每个indexFile`以一个时间戳命名`且由三部分构成：indexHeader，slots槽位，indexes索引数据

- 每个indexFile文件中包含500w个slot槽。而每个slot槽又可能会挂载很多的index索引单元
- 在实际存储时，Indexes是在Slots后面的，而在逻辑理解上我们一般以hashmap类别，index以拉链法挂载在固定slot上

<img src="http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/2bb5d692457347fc93ba757e9743b177.png" alt="在这里插入图片描述" style="zoom:50%;" />

---

indexHeader：固定四十个字节

- **beginTimestamp(8字节)**：该indexFile中第一条消息的存储时间
- **endTimestamp(8字节)**：该indexFile中目前最后一条消息存储时间
- **beginPhyoffset**(8字节)：该indexFile中第一条消息在commitlog中的偏移量commitlog offset
- **endPhyoffset(8字节)**：该indexFile中目前最后一条消息在commitlog中的偏移量commitlog offset
- **hashSlotCount**(4字节)：已经填充有index的slot数量（并不是每个slot槽下都挂载有index索引单元，这里统计的是所有挂载了index索引单元的slot槽的数量）
- **indexCount(4字节)**：该indexFile中包含的索引单元个数（统计出当前indexFile中所有slot槽下挂载的所有index索引单元的数量之和）

---

**index索引单元**：固定20字节

- **keyHash**：消息中指定的业务key的hash值
- **phyOffset**：当前key对应的消息在commitlog中的偏移量commitlog offset
- **timeDiff**：当前key对应消息的存储时间与当前indexFile创建时间的时间差
- **preIndexNo**：当前slot中该index索引单元的前一个index索引单元的indexNo

---

index索引单元挂载流程

- key的hash值 % 500w的结果即为slot槽位，然后将该slot值修改为该index索引单元的indexNo，从而保证`slot中始终存放的是其下最新的index索引单元的indexNo`
- 这样的话，`只要找到了slot就可以找到其最新的index索引单元，而通过这个index索引单元就可以找到其之前的所有index索引单元`
- `indexNo`是一个在`indexFile中的流水号`，从0开始`依次递增`。即在一个indexFile中所有indexNo是以此递增的
- `indexNo在index索引单元中是没有体现的，其是通过indexes中依次数出来的`

---

indexFile的创建

- *当第一条带key的消息发送来后，系统发现没有indexFile，此时会创建第一个indexFile文件*
- 当带key的消息发送到来后，系统会找到最新的indexFile，并从其indexHeader的最后4字节中读取到indexCount。若indexCount >= 2000w时，会创建新的indexFile

---

查询流程

```shell
#计算指定消息key的slot槽位序号：
slot槽位序号 = key的hash % 500w         (式子1)

#计算槽位序号为n的slot在indexFile中的起始位置：
slot(n)位置 = 40 + (n - 1) * 4         (式子2)

#计算indexNo为m的indexs在indexFile中的位置：
index(m)位置 = 40 + 500w * 4 + (m - 1) * 20   (式子3)
```

![在这里插入图片描述](http://aikaid-img.oss-cn-shanghai.aliyuncs.com/img/b87f8a77ce6e466d96f0bda2874a76d8.png)

## 5.3 消息的清理

- `消息清理单位`： 消息是被顺序存储在commitlog文件的，且消息大小不定长，所以消息的清理是不可能以消息为单位进行清理的，而是`以commitlog文件为单位进行清理`的。否则会急剧下降清理效率，并实现逻辑复杂。
- `清理时间`： commitlog文件存在一个过期时间，默认为72小时，即三天
  - `文件过期`，且到达`清理时间点`（默认为凌晨4点）后，自动清理过期文件
  - `文件过期`，且磁盘空间占用率已达`过期清理警戒线`（默认75%）后，无论是否达到清理时间点，都会自动清理过期文件
  - `磁盘占用率达到清理警戒线`（默认85%）后，开始按照设定好的规则清理文件，无论是否过期。默认会从最老的文件开始清理
  - `磁盘占用率达到系统危险警戒线`（默认90%）后，Broker将拒绝消息写入

## 5.4 消息的返回

如果是第一次拉取，如何定位第一条消息的位置

- 首先Broker会找到MessageQueue对应的ConsumerQueue，从里面找到这条消息的offset
- 然后通过offset去CommitLog中读取消息数据，把消息返回给消费者
- 当消费者消费完这条消息后，会提交一个消费的进度给Broker，Broker会记录下一个ConsumerOffset来标记我们的消费进度
- 下次消费者再去这个MessageQueue中拉取消息时，就会从记录的消费位置继续拉取消息，而不用从头获取了

# 6. Message

## 6.1 普通消息

## 6.2 顺序消息

顺序消息是指消息的消费顺序和产生顺序相同，比如订单的生成、付款、发货，这3 个消息必须按顺序处理才行

- 全局顺序消息：某个Topic下的所有消息都要保证顺序
- 部分顺序消息：只要每一组消息被顺序消费即可

## 6.3 延时消息

## 6.4 事务消息

## 6.5 批量消息

## 6.6 消息过滤

## 6.7 消息发送重试机制

## 6.8 消息消费重试机制

## 6.9 死信队列
