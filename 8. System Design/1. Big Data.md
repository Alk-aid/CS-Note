# 1. 概述

海量数据主要存在的问题:

- 时间上: 数据量太大, 短时间无法处理; 使用Bloom Filter / Hash / bit-map / 堆 / 数据库或倒排索引 / trie 树
- 空间上: 数据量太大, 无法一次性装入内存;  大而化小，分而治之(hash映射);



# 2. 分治/hash/排序

1. 思路: 先映射, 后统计, 最后排序

- `分而治之/hash映射`: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件
- `hash_map统计`: 当大文件转化了小文件，可以采用常规的hash_map(ip，value)来进行频率统计
- `堆/快速排序`: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP

2. 海量日志数据，提取出某日访问百度次数最多的那个IP

>- 首先是找到这一天访问百度的 IP, 然后将他们放到同一个文件中去
>- 然后使用hash 函数将整个大文件映射为1000 个小文件(因为IP 相同的hash 也相同,所以一定能够放到相同的文件上)
>- 然后找出每个小文件出现频率最大的 IP

3. 寻找热门查询，300万个查询字符串中统计最热门的10个查询

>分析可知 最多占用内存3M*1K/4=0.75G, 所以可以全部都放到内存当中
>
>- hash_map统计: key 为字符串,value 为该字符串出现的次数
>- 堆排序: 
>- O(N) + N' * O(logK)，(N为1000万，N’为300万)

4. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

> 

5. 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10

>  

6. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序

>  

7. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url

>  

8. 怎么在海量数据中找出重复次数最多的一个

>  

9. 上千万或上亿数据(有重复)，统计其中出现次数最多的前N个数据

>  

10. 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析

>  

11. 一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解

>  

12. 100w个数中找出最大的100个数

> 

# 3. Bitmap & Bloom Filter

# 4. 双层桶划分

# 5. Tire树/数据库/倒排索引

# 6. 外排序

# 7. Map & Reduce

