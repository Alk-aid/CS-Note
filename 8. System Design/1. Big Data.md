# 1. 概述

海量数据主要存在的问题:

- 时间上: 数据量太大, 短时间无法处理; 使用Bloom Filter / Hash / bit-map / 堆 / 数据库或倒排索引 / trie 树
- 空间上: 数据量太大, 无法一次性装入内存;  大而化小，分而治之(hash映射);



# 2. 分治/hash/排序

1. 思路: 先映射, 后统计, 最后排序

- `分而治之/hash映射`: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件
- `hash_map统计`: 当大文件转化了小文件，可以采用常规的hash_map(ip，value)来进行频率统计
- `堆/快速排序`: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP

2. 海量日志数据，提取出某日访问百度次数最多的那个IP

>- 首先是找到这一天访问百度的 IP, 然后将他们放到同一个文件中去
>- 然后使用hash 函数将整个大文件映射为1000 个小文件(因为IP 相同的hash 也相同,所以一定能够放到相同的文件上)
>- 然后找出每个小文件出现频率最大的 IP

3. 寻找热门查询，300万个查询字符串中统计最热门的10个查询

>分析可知 最多占用内存3M*1K/4=0.75G, 所以可以全部都放到内存当中
>
>- hash_map统计: key 为字符串,value 为该字符串出现的次数
>- 堆排序: 
>- O(N) + N' * O(logK)，(N为1000万，N’为300万)

4. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

> - 对每个单词取 hash(x) % 5000, 放到5000 个小文件中, 这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分
> - 使用 hashmap对每个小文件统计单词的次数, 使用堆得到最多的 100 个
> - 再把100个词及相应的频率存入文件，这样又得到了5000个文件
> - 最后就是把这5000个文件进行归并排序

5. 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10

> 1.  数据不重复
>
> - 每台电脑求出对应的 top10
> - 然后将 100 台电脑的 top10 放到一起,在使用堆排序求 top10
>
> 2. 数据重复
>
> - 遍历一次所有数据, 重新hash取摸，如此使得同一个元素只出现在单独的一台电脑中
> - 然后再使用方案一的方法

6. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序

> - 将重复数据放到一个文件中: 顺序遍历 10 个文件, 按照hash(query)%10的结果将query写入到另外10个文件(
> - 找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数, 然后使用排序进行按照出现次数进行排序
> - 这样得到 10 个排好序的文件以后, 使用归并进行排序

7. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url

> - 遍历 a, 对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件(a0 - a999)
> - 同样的手法遍历 b, 然后根据所取得的值将url分别存储到1000个小文件(b0 - b999)
> - 求每对小文件ai和bi中相同的url时，可以把ai的url存储到hash_set/hash_map中。然后遍历bi的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了

8. 100w个数中找出最大的100个数

> - 使用一个大小为 100 的最小堆,遍历就可以了

# 3. Bitmap & Bloom Filter

1. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?

> 如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url(注意会有一定的错误率)

2. 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数

> 采用2-Bitmap(每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义)进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可

3. 给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢?

> 

4. 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中?

> 用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在

# 4. 双层桶划分

1. 5亿个int找它们的中位数

> 1. 
>
> - 顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中
> - 通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）
> - 重复操作,直到可以装进内存, 进行快速排序, 找出中位数
>
> 2.  
>
> - 分治到每个文件能读取到内存中 ，每一个文件内排序，然后外排序，最后整体有序，然后直接找5亿/2的下标和下一个数的平均数



# 5. Tire树/数据库/倒排索引

# 6. 外排序

1. 假设文件中整数个数为N(N是亿级的)，整数之间用空格分开
2. 首先分多次从该文件中读取M（十万级）个整数，每次将M个整数在内存中使用内部排序之后存入临时文件，这样就得到多个外部文件
3. 对应于多个外部文件，我们可以利用多路归并将各个临时文件中的数据一边读入内存，一边进行归并输出到输出文件
4. 显然，该排序算法需要对每个整数做2次磁盘读和2次磁盘写。（如果根据初始外部文件的个数设置归并的路数，则会对每个整数做多次读/写)

# 7. Map & Reduce

